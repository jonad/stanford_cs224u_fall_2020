{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework and bake-off: word-level entailment with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts\"\n",
    "__version__ = \"CS224u, Stanford, Fall 2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Set-up](#Set-up)\n",
    "1. [Data](#Data)\n",
    "1. [Baseline](#Baseline)\n",
    "  1. [Representing words: vector_func](#Representing-words:-vector_func)\n",
    "  1. [Combining words into inputs: vector_combo_func](#Combining-words-into-inputs:-vector_combo_func)\n",
    "  1. [Classifier model](#Classifier-model)\n",
    "  1. [Baseline results](#Baseline-results)\n",
    "1. [Homework questions](#Homework-questions)\n",
    "  1. [Hypothesis-only baseline [2 points]](#Hypothesis-only-baseline-[2-points])\n",
    "  1. [Alternatives to concatenation [2 points]](#Alternatives-to-concatenation-[2-points])\n",
    "  1. [A deeper network [2 points]](#A-deeper-network-[2-points])\n",
    "  1. [Your original system [3 points]](#Your-original-system-[3-points])\n",
    "1. [Bake-off [1 point]](#Bake-off-[1-point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general problem is word-level natural language inference. Training examples are pairs of words $(w_{L}, w_{R}), y$ with $y = 1$ if $w_{L}$ entails $w_{R}$, otherwise $0$.\n",
    "\n",
    "The homework questions below ask you to define baseline models for this and develop your own system for entry in the bake-off, which will take place on a held-out test-set distributed at the start of the bake-off. (Thus, all the data you have available for development is available for training your final system before the bake-off begins.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [the first notebook in this unit](nli_01_task_and_data.ipynb) for set-up instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_shallow_neural_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4cdc4c178eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_shallow_neural_classifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchShallowNeuralClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_shallow_neural_classifier'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "import nli\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME = 'data'\n",
    "\n",
    "NLIDATA_HOME = os.path.join(DATA_HOME, 'nlidata')\n",
    "\n",
    "wordentail_filename = os.path.join(\n",
    "    NLIDATA_HOME, 'nli_wordentail_bakeoff_data.json')\n",
    "\n",
    "GLOVE_HOME = os.path.join(DATA_HOME, 'glove.6B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "I've processed the data into a train/dev split that is designed to put some pressure on our models to actually learn these semantic relations, as opposed to exploiting regularities in the sample. \n",
    "\n",
    "The defining feature of the dataset is that the `train` and `dev` __vocabularies__ are disjoint. That is, if a word `w` appears in a training pair, it does not occur in any text pair. It follows from this that there are also no word-pairs shared between train and dev, as you would expect. This should require your models to learn abstract relationships, as opposed to memorizing incidental properties of individual words in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(wordentail_filename) as f:\n",
    "    wordentail_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys are the splits plus a list giving the vocabulary for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordentail_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f2abda4d2b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwordentail_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wordentail_data' is not defined"
     ]
    }
   ],
   "source": [
    "wordentail_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordentail_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f69167ad5be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwordentail_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wordentail_data' is not defined"
     ]
    }
   ],
   "source": [
    "wordentail_data['train'][: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nli' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2cd147921473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocab_overlap_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordentail_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nli' is not defined"
     ]
    }
   ],
   "source": [
    "nli.get_vocab_overlap_size(wordentail_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because no words are shared between `train` and `dev`, no pairs are either:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nli' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9a04b587a018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pair_overlap_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordentail_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nli' is not defined"
     ]
    }
   ],
   "source": [
    "nli.get_pair_overlap_size(wordentail_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7000\n",
       "1    1283\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(wordentail_data['train'])[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a challenging label distribution – there are more than 5 times as more non-entailment cases as entailment cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in deep learning, __feature representation is vital and requires care!__ For our task, feature representation has two parts: representing the individual words and combining those representations into a single network input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing words: vector_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider two baseline word representations methods:\n",
    "\n",
    "1. Random vectors (as returned by `utils.randvec`).\n",
    "1. 50-dimensional GloVe representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randvec(w, n=50, lower=-1.0, upper=1.0):\n",
    "    \"\"\"Returns a random vector of length `n`. `w` is ignored.\"\"\"\n",
    "    return utils.randvec(n=n, lower=lower, upper=upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove50():\n",
    "    glove_src = os.path.join(GLOVE_HOME, 'glove.6B.50d.txt')\n",
    "    # Creates a dict mapping strings (words) to GloVe vectors:\n",
    "    GLOVE = utils.glove2dict(glove_src)\n",
    "    return GLOVE\n",
    "\n",
    "GLOVE = load_glove50()\n",
    "\n",
    "def glove_vec(w):\n",
    "    \"\"\"Return `w`'s GloVe representation if available, else return\n",
    "    a random vector.\"\"\"\n",
    "    return GLOVE.get(w, randvec(w, n=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining words into inputs: vector_combo_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we decide how to combine the two word vectors into a single representation. In more detail, where `u` is a vector representation of the left word and `v` is a vector representation of the right word, we need a function `vector_combo_func` such that `vector_combo_func(u, v)` returns a new input vector `z` of dimension `m`. A simple example is concatenation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_concatenate(u, v):\n",
    "    \"\"\"Concatenate np.array instances `u` and `v` into a new np.array\"\"\"\n",
    "    return np.concatenate((u, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vector_combo_func` could instead be vector average, vector difference, etc. (even combinations of those) – there's lots of space for experimentation here; [homework question 2](#Alternatives-to-concatenation-[2-points]) below pushes you to do some exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier model\n",
    "\n",
    "For a baseline model, I chose `TorchShallowNeuralClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TorchShallowNeuralClassifier(early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline results\n",
    "\n",
    "The following puts the above pieces together, using `vector_func=glove_vec`, since `vector_func=randvec` seems so hopelessly misguided for our problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 49. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.325287878513336"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.868     0.952     0.908      1732\n",
      "           1      0.500     0.249     0.332       334\n",
      "\n",
      "    accuracy                          0.838      2066\n",
      "   macro avg      0.684     0.600     0.620      2066\n",
      "weighted avg      0.808     0.838     0.815      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_experiment = nli.wordentail_experiment(\n",
    "    train_data=wordentail_data['train'],\n",
    "    assess_data=wordentail_data['dev'],\n",
    "    model=net,\n",
    "    vector_func=glove_vec,\n",
    "    vector_combo_func=vec_concatenate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework questions\n",
    "\n",
    "Please embed your homework responses in this notebook, and do not delete any cells from the notebook. (You are free to add as many cells as you like as part of your responses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis-only baseline [2 points]\n",
    "\n",
    "During our discussion of SNLI and MultiNLI, we noted that a number of research teams have shown that hypothesis-only baselines for NLI tasks can be remarkably robust. This question asks you to explore briefly how this baseline affects our task.\n",
    "\n",
    "For this problem, submit two functions:\n",
    "\n",
    "1. A `vector_combo_func` function called `hypothesis_only` that simply throws away the premise, using the unmodified hypothesis (second) vector as its representation of the example.\n",
    "\n",
    "1. A function called `run_hypothesis_only_evaluation` that does the following:\n",
    "    1. Loops over the two `vector_combo_func` values `vec_concatenate` and `hypothesis_only`, calling `nli.wordentail_experiment` to train on the 'train' portion and assess on the 'dev' portion, with `glove_vec` as the `vector_func`. So that the results are consistent, use an `sklearn.linear_model.LogisticRegression` with default parameters as the model.\n",
    "    1. Returns a `dict` mapping `function_name` strings to the 'macro-F1' score for that pair, as returned by the call to `nli.wordentail_experiment`. (Tip: you can get the `str` name of, e.g., `hypothesis_only` with `hypothesis_only.__name__`.)\n",
    "    \n",
    "The functions `test_hypothesis_only` and `test_run_hypothesis_only_evaluation` will help ensure that your functions have the desired logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis_only(u, v):\n",
    "    ##### YOUR CODE HERE\n",
    "    return v\n",
    "\n",
    "\n",
    "def run_hypothesis_only_evaluation():\n",
    "    ##### YOUR CODE HERE\n",
    "    results = {}\n",
    "    for vector_combo_function in [vec_concatenate, hypothesis_only]:\n",
    "        print(vector_combo_function.__name__)\n",
    "        result = nli.wordentail_experiment(train_data=wordentail_data['train'],\n",
    "                                  assess_data=wordentail_data['dev'],\n",
    "                                  model=net,\n",
    "                                  vector_func=glove_vec,\n",
    "                                  vector_combo_func=vector_combo_function)\n",
    "        results[vector_combo_function.__name__] = result['macro-F1']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hypothesis_only(hypothesis_only):\n",
    "    v = hypothesis_only(1, 2)\n",
    "    assert v == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hypothesis_only(hypothesis_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run_hypothesis_only_evaluation(run_hypothesis_only_evaluation):\n",
    "    results = run_hypothesis_only_evaluation()\n",
    "    assert all(x in results for x in ('hypothesis_only', 'vec_concatenate')), \\\n",
    "        (\"The return value of `run_hypothesis_only_evaluation` does not \"\n",
    "         \"have the intended kind of keys.\")\n",
    "    assert isinstance(results['vec_concatenate'], float), \\\n",
    "        (\"The values of the `run_hypothesis_only_evaluation` result \"\n",
    "         \"should be floats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finished epoch 1 of 1000; error is 5.084521412849426"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 41. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.4330197274684906"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.868     0.941     0.903      1732\n",
      "           1      0.458     0.260     0.332       334\n",
      "\n",
      "    accuracy                          0.831      2066\n",
      "   macro avg      0.663     0.601     0.618      2066\n",
      "weighted avg      0.802     0.831     0.811      2066\n",
      "\n",
      "hypothesis_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 56. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.531109631061554"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.851     0.975     0.909      1732\n",
      "           1      0.469     0.114     0.183       334\n",
      "\n",
      "    accuracy                          0.836      2066\n",
      "   macro avg      0.660     0.544     0.546      2066\n",
      "weighted avg      0.789     0.836     0.791      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_run_hypothesis_only_evaluation(run_hypothesis_only_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatives to concatenation [2 points]\n",
    "\n",
    "We've so far just used vector concatenation to represent the premise and hypothesis words. This question asks you to explore two simple alternative:\n",
    "\n",
    "1. Write a function `vec_diff` that, for a given pair of vector inputs `u` and `v`, returns the element-wise difference between `u` and `v`.\n",
    "\n",
    "1. Write a function `vec_max` that, for a given pair of vector inputs `u` and `v`, returns the element-wise max values between `u` and `v`.\n",
    "\n",
    "You needn't include your uses of `nli.wordentail_experiment` with these functions, but we assume you'll be curious to see how they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_diff(u, v):\n",
    "    ##### YOUR CODE HERE\n",
    "    return u - v\n",
    "\n",
    "\n",
    "def vec_max(u, v):\n",
    "    ##### YOUR CODE HERE\n",
    "    return np.maximum(u, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vec_diff(vec_diff):\n",
    "    u = np.array([10.2, 8.1])\n",
    "    v = np.array([1.2, -7.1])\n",
    "    result = vec_diff(u, v)\n",
    "    expected = np.array([9.0, 15.2])\n",
    "    assert np.array_equal(result, expected), \\\n",
    "        \"Expected {}; got {}\".format(expected, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_diff(vec_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vec_max(vec_max):\n",
    "    u = np.array([1.2,  8.1])\n",
    "    v = np.array([10.2, -7.1])\n",
    "    result = vec_max(u, v)\n",
    "    expected = np.array([10.2, 8.1])\n",
    "    assert np.array_equal(result, expected), \\\n",
    "        \"Expected {}; got {}\".format(expected, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec_max(vec_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_evaluation():\n",
    "    results = {}\n",
    "    for vector_combo_function in [vec_concatenate, hypothesis_only, vec_diff, vec_max]:\n",
    "        print(vector_combo_function.__name__)\n",
    "        result = nli.wordentail_experiment(train_data=wordentail_data['train'],\n",
    "                                  assess_data=wordentail_data['dev'],\n",
    "                                  model=net,\n",
    "                                  vector_func=glove_vec,\n",
    "                                  vector_combo_func=vector_combo_function)\n",
    "        results[vector_combo_function.__name__] = result['macro-F1']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finished epoch 1 of 1000; error is 4.411177694797516"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 31. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.5497706532478333"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.866     0.943     0.903      1732\n",
      "           1      0.453     0.246     0.318       334\n",
      "\n",
      "    accuracy                          0.830      2066\n",
      "   macro avg      0.660     0.594     0.611      2066\n",
      "weighted avg      0.800     0.830     0.808      2066\n",
      "\n",
      "hypothesis_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 28. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.896387964487076"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.849     0.922     0.884      1732\n",
      "           1      0.274     0.153     0.196       334\n",
      "\n",
      "    accuracy                          0.798      2066\n",
      "   macro avg      0.562     0.537     0.540      2066\n",
      "weighted avg      0.756     0.798     0.773      2066\n",
      "\n",
      "vec_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 18. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 3.054068475961685"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.859     0.895     0.877      1732\n",
      "           1      0.305     0.240     0.268       334\n",
      "\n",
      "    accuracy                          0.789      2066\n",
      "   macro avg      0.582     0.567     0.573      2066\n",
      "weighted avg      0.770     0.789     0.778      2066\n",
      "\n",
      "vec_max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 45. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.8190397918224335"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.854     0.954     0.901      1732\n",
      "           1      0.392     0.153     0.220       334\n",
      "\n",
      "    accuracy                          0.825      2066\n",
      "   macro avg      0.623     0.554     0.561      2066\n",
      "weighted avg      0.779     0.825     0.791      2066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec_concatenate': 0.6107024273186759,\n",
       " 'hypothesis_only': 0.5402142431212199,\n",
       " 'vec_diff': 0.5725766042090559,\n",
       " 'vec_max': 0.5605681006279848}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_multiple_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A deeper network [2 points]\n",
    "\n",
    "It is very easy to subclass `TorchShallowNeuralClassifier` if all you want to do is change the network graph: all you have to do is write a new `build_graph`. If your graph has new arguments that the user might want to set, then you should also redefine `__init__` so that these values are accepted and set as attributes.\n",
    "\n",
    "For this question, please subclass `TorchShallowNeuralClassifier` so that it defines the following graph:\n",
    "\n",
    "$$\\begin{align}\n",
    "h_{1} &= xW_{1} + b_{1} \\\\\n",
    "r_{1} &= \\textbf{Bernoulli}(1 - \\textbf{dropout_prob}, n) \\\\\n",
    "d_{1} &= r_1 * h_{1} \\\\\n",
    "h_{2} &= f(d_{1}) \\\\\n",
    "h_{3} &= h_{2}W_{2} + b_{2}\n",
    "\\end{align}$$\n",
    "\n",
    "Here, $r_{1}$ and $d_{1}$ define a dropout layer: $r_{1}$ is a random binary vector of dimension $n$, where the probability of a value being $1$ is given by $1 - \\textbf{dropout_prob}$. $r_{1}$ is multiplied element-wise by our first hidden representation, thereby zeroing out some of the values. The result is fed to the user's activation function $f$, and the result of that is fed through another linear layer to produce $h_{3}$. (Inside `TorchShallowNeuralClassifier`, $h_{3}$ is the basis for a softmax classifier; no activation function is applied to it because the softmax scaling is handled internally by the loss function.)\n",
    "\n",
    "For your implementation, please use `nn.Sequential`, `nn.Linear`, and `nn.Dropout` to define the required layers.\n",
    "\n",
    "For comparison, using this notation, `TorchShallowNeuralClassifier` defines the following graph:\n",
    "\n",
    "$$\\begin{align}\n",
    "h_{1} &= xW_{1} + b_{1} \\\\\n",
    "h_{2} &= f(h_{1}) \\\\\n",
    "h_{3} &= h_{2}W_{2} + b_{2}\n",
    "\\end{align}$$\n",
    "\n",
    "The following code starts this sub-class for you, so that you can concentrate on `build_graph`. Be sure to make use of `self.dropout_prob`.\n",
    "\n",
    "For this problem, submit just your completed  `TorchDeepNeuralClassifier`. You needn't evaluate it, though we assume you will be keen to do that!\n",
    "\n",
    "You can use `test_TorchDeepNeuralClassifier` to ensure that your network has the intended structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TorchDeepNeuralClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self, dropout_prob=0.7, **kwargs):\n",
    "        self.dropout_prob = dropout_prob\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Complete this method!\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        an `nn.Module` instance, which can be a free-standing class you\n",
    "        write yourself, as in `torch_rnn_classifier`, or the outpiut of\n",
    "        `nn.Sequential`, as in `torch_shallow_neural_classifier`.\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "        ##### YOUR CODE HERE\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.Dropout(self.dropout_prob),\n",
    "            self.hidden_activation,\n",
    "            nn.Linear(self.hidden_dim, self.n_classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_TorchDeepNeuralClassifier(TorchDeepNeuralClassifier):\n",
    "    dropout_prob = 0.55\n",
    "    assert hasattr(TorchDeepNeuralClassifier(), \"dropout_prob\"), \\\n",
    "        \"TorchDeepNeuralClassifier must have an attribute `dropout_prob`.\"\n",
    "    try:\n",
    "        inst = TorchDeepNeuralClassifier(dropout_prob=dropout_prob)\n",
    "    except TypeError:\n",
    "        raise TypeError(\"TorchDeepNeuralClassifier must allow the user \"\n",
    "                        \"to set `dropout_prob` on initialization\")\n",
    "    inst.input_dim = 10\n",
    "    inst.n_classes_ = 5\n",
    "    graph = inst.build_graph()\n",
    "    assert len(graph) == 4, \\\n",
    "        \"The graph should have 4 layers; yours has {}\".format(len(graph))\n",
    "    expected = {\n",
    "        0: 'Linear',\n",
    "        1: 'Dropout',\n",
    "        2: 'Tanh',\n",
    "        3: 'Linear'}\n",
    "    for i, label in expected.items():\n",
    "        name = graph[i].__class__.__name__\n",
    "        assert label in name, \\\n",
    "            (\"The {} layer of the graph should be a {} layer; \"\n",
    "            \"yours is {}\".format(i, label, name))\n",
    "    assert graph[1].p == dropout_prob, \\\n",
    "        (\"The user's value for `dropout_prob` should be the value of \"\n",
    "         \"`p` for the Dropout layer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TorchDeepNeuralClassifier(TorchDeepNeuralClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(TorchDeepNeuralClassifier(), \"dropout_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_net = TorchDeepNeuralClassifier(dropout_prob=0.5)\n",
    "def run_multiple_evaluation():\n",
    "    results = {}\n",
    "    for vector_combo_function in [vec_concatenate, hypothesis_only, vec_diff, vec_max]:\n",
    "        print(vector_combo_function.__name__)\n",
    "        result = nli.wordentail_experiment(train_data=wordentail_data['train'],\n",
    "                                  assess_data=wordentail_data['dev'],\n",
    "                                  model=deep_net,\n",
    "                                  vector_func=glove_vec,\n",
    "                                  vector_combo_func=vector_combo_function)\n",
    "        results[vector_combo_function.__name__] = result['macro-F1']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 127. Training loss did not improve more than tol=1e-05. Final error is 2.469067171216011."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.862     0.969     0.912      1732\n",
      "           1      0.550     0.198     0.291       334\n",
      "\n",
      "    accuracy                          0.844      2066\n",
      "   macro avg      0.706     0.583     0.602      2066\n",
      "weighted avg      0.812     0.844     0.812      2066\n",
      "\n",
      "hypothesis_only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 82. Training loss did not improve more than tol=1e-05. Final error is 3.1172206103801727."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.852     0.975     0.909      1732\n",
      "           1      0.482     0.123     0.196       334\n",
      "\n",
      "    accuracy                          0.837      2066\n",
      "   macro avg      0.667     0.549     0.552      2066\n",
      "weighted avg      0.792     0.837     0.794      2066\n",
      "\n",
      "vec_diff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 42. Training loss did not improve more than tol=1e-05. Final error is 3.469692200422287."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.849     0.977     0.909      1732\n",
      "           1      0.466     0.102     0.167       334\n",
      "\n",
      "    accuracy                          0.836      2066\n",
      "   macro avg      0.658     0.540     0.538      2066\n",
      "weighted avg      0.787     0.836     0.789      2066\n",
      "\n",
      "vec_max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 43. Training loss did not improve more than tol=1e-05. Final error is 3.147583246231079."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.852     0.966     0.905      1732\n",
      "           1      0.422     0.129     0.197       334\n",
      "\n",
      "    accuracy                          0.831      2066\n",
      "   macro avg      0.637     0.547     0.551      2066\n",
      "weighted avg      0.782     0.831     0.791      2066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec_concatenate': 0.60160065923589,\n",
       " 'hypothesis_only': 0.5524709351841913,\n",
       " 'vec_diff': 0.5380347278333855,\n",
       " 'vec_max': 0.5512753683625243}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_multiple_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your original system [3 points]\n",
    "\n",
    "This is a simple dataset, but its \"word-disjoint\" nature ensures that it's a challenging one, and there are lots of modeling strategies one might adopt. \n",
    "\n",
    "You are free to do whatever you like. We require only that your system differ in some way from those defined in the preceding questions. They don't have to be completely different, though. For example, you might want to stick with the model but represent examples differently, or the reverse.\n",
    "\n",
    "You are free to use different pretrained word vectors and the like.\n",
    "\n",
    "Please embed your code in this notebook so that we can rerun it.\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies.  We also ask that you report the best score your system got during development, just to help us understand how systems performed overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self, dropout_prob=0.7, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.params += ['dropout_prob']\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Complete this method!\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        an `nn.Module` instance, which can be a free-standing class you\n",
    "        write yourself, as in `torch_rnn_classifier`, or the outpiut of\n",
    "        `nn.Sequential`, as in `torch_shallow_neural_classifier`.\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "        ##### YOUR CODE HERE\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.Dropout(self.dropout_prob),\n",
    "            self.hidden_activation,\n",
    "            nn.Linear(self.hidden_dim, self.n_classes_))\n",
    "    \n",
    "    def build_dataset(self, X, y=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        self.input_dim = X.shape[1]\n",
    "        \n",
    "        if y is None:\n",
    "            X = torch.FloatTensor(X)\n",
    "            dataset = torch.utils.data.TensorDataset(X)\n",
    "        else:\n",
    "            self.classes_ = sorted(set(y))\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            y = [class2index[label] for label in y]\n",
    "            X, y = oversample.fit_resample(X, y)\n",
    "            X = torch.FloatTensor(X)\n",
    "            y = torch.tensor(y)\n",
    "            dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        return dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_glove300():\n",
    "#     glove_src = os.path.join(GLOVE_HOME, 'glove.6B.300d.txt')\n",
    "#     # Creates a dict mapping strings (words) to GloVe vectors:\n",
    "#     GLOVE = utils.glove2dict(glove_src)\n",
    "#     return GLOVE\n",
    "\n",
    "# GLOVE = load_glove300()\n",
    "\n",
    "# def glove_vec(w):\n",
    "#     \"\"\"Return `w`'s GloVe representation if available, else return\n",
    "#     a random vector.\"\"\"\n",
    "#     return GLOVE.get(w, randvec(w, n=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MYClassifier(dropout_prob=0.4, eta=0.001, hidden_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 181. Training loss did not improve more than tol=1e-05. Final error is 0.03622982953675091."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.890     0.889     0.889      1732\n",
      "           1      0.427     0.428     0.428       334\n",
      "\n",
      "    accuracy                          0.815      2066\n",
      "   macro avg      0.658     0.659     0.658      2066\n",
      "weighted avg      0.815     0.815     0.815      2066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': MYClassifier(\n",
       " \tbatch_size=1028,\n",
       " \tmax_iter=1000,\n",
       " \teta=0.001,\n",
       " \toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       " \tl2_strength=0,\n",
       " \tgradient_accumulation_steps=1,\n",
       " \tmax_grad_norm=None,\n",
       " \tvalidation_fraction=0.1,\n",
       " \tearly_stopping=False,\n",
       " \tn_iter_no_change=10,\n",
       " \twarm_start=False,\n",
       " \ttol=1e-05,\n",
       " \thidden_dim=300,\n",
       " \thidden_activation=Tanh(),\n",
       " \tdropout_prob=0.4),\n",
       " 'train_data': [[['abode', 'house'], 1],\n",
       "  [['abortion', 'anaemia'], 0],\n",
       "  [['abortion', 'aneurysm'], 0],\n",
       "  [['abortion', 'blindness'], 0],\n",
       "  [['abortion', 'deafness'], 0],\n",
       "  [['abortion', 'death'], 0],\n",
       "  [['abortion', 'headache'], 0],\n",
       "  [['abortion', 'hemiplegia'], 0],\n",
       "  [['abortion', 'lesion'], 0],\n",
       "  [['abortion', 'pain'], 0],\n",
       "  [['abortion', 'palsy'], 0],\n",
       "  [['abortion', 'paralysis'], 0],\n",
       "  [['abortion', 'rickets'], 0],\n",
       "  [['abortion', 'sore'], 0],\n",
       "  [['abortion', 'stenosis'], 0],\n",
       "  [['abortion', 'sterility'], 0],\n",
       "  [['abortion', 'ulcer'], 0],\n",
       "  [['abrasion', 'wound'], 1],\n",
       "  [['abscess', 'alcohol'], 0],\n",
       "  [['abscess', 'aneurysm'], 0],\n",
       "  [['abscess', 'anthrax'], 0],\n",
       "  [['abscess', 'bacteremia'], 0],\n",
       "  [['abscess', 'bite'], 0],\n",
       "  [['abscess', 'bronchitis'], 0],\n",
       "  [['abscess', 'catarrh'], 0],\n",
       "  [['abscess', 'cervicitis'], 0],\n",
       "  [['abscess', 'chill'], 0],\n",
       "  [['abscess', 'contraction'], 0],\n",
       "  [['abscess', 'death'], 0],\n",
       "  [['abscess', 'effusion'], 0],\n",
       "  [['abscess', 'empyema'], 0],\n",
       "  [['abscess', 'exertion'], 0],\n",
       "  [['abscess', 'fever'], 0],\n",
       "  [['abscess', 'gangrene'], 0],\n",
       "  [['abscess', 'gonorrhea'], 0],\n",
       "  [['abscess', 'haemorrhage'], 0],\n",
       "  [['abscess', 'hematoma'], 0],\n",
       "  [['abscess', 'hypertension'], 0],\n",
       "  [['abscess', 'ingestion'], 0],\n",
       "  [['abscess', 'injury'], 0],\n",
       "  [['abscess', 'intoxication'], 0],\n",
       "  [['abscess', 'lesion'], 0],\n",
       "  [['abscess', 'measles'], 0],\n",
       "  [['abscess', 'migraine'], 0],\n",
       "  [['abscess', 'necrosis'], 0],\n",
       "  [['abscess', 'pain'], 0],\n",
       "  [['abscess', 'pleurisy'], 0],\n",
       "  [['abscess', 'sinusitis'], 0],\n",
       "  [['abscess', 'sputum'], 0],\n",
       "  [['abscess', 'strain'], 0],\n",
       "  [['abscess', 'symptom'], 1],\n",
       "  [['abscess', 'vomiting'], 0],\n",
       "  [['abundance', 'destitution'], 0],\n",
       "  [['abuse', 'allegation'], 0],\n",
       "  [['abuse', 'beating'], 0],\n",
       "  [['abuse', 'complaint'], 0],\n",
       "  [['abuse', 'conspiracy'], 0],\n",
       "  [['abuse', 'death'], 0],\n",
       "  [['abuse', 'drug'], 0],\n",
       "  [['abuse', 'exploitation'], 0],\n",
       "  [['abuse', 'fraud'], 0],\n",
       "  [['abuse', 'gang'], 0],\n",
       "  [['abuse', 'involvement'], 1],\n",
       "  [['abuse', 'irregularity'], 1],\n",
       "  [['abuse', 'malpractice'], 0],\n",
       "  [['abuse', 'massacre'], 0],\n",
       "  [['abuse', 'molestation'], 0],\n",
       "  [['abuse', 'offence'], 1],\n",
       "  [['abuse', 'paedophilia'], 0],\n",
       "  [['abuse', 'porn'], 0],\n",
       "  [['abuse', 'prostitution'], 0],\n",
       "  [['abuse', 'racism'], 0],\n",
       "  [['abuse', 'rape'], 0],\n",
       "  [['abuse', 'repression'], 0],\n",
       "  [['abuse', 'scandal'], 0],\n",
       "  [['abuse', 'shooting'], 0],\n",
       "  [['abuse', 'smuggling'], 0],\n",
       "  [['abuse', 'terrorism'], 0],\n",
       "  [['abuse', 'violation'], 1],\n",
       "  [['abuse', 'violence'], 0],\n",
       "  [['acacia', 'birch'], 0],\n",
       "  [['acacia', 'bole'], 0],\n",
       "  [['acacia', 'connexion'], 0],\n",
       "  [['acacia', 'cortex'], 0],\n",
       "  [['acacia', 'crown'], 0],\n",
       "  [['acacia', 'cypress'], 0],\n",
       "  [['acacia', 'elm'], 0],\n",
       "  [['acacia', 'flower'], 0],\n",
       "  [['acacia', 'impact'], 0],\n",
       "  [['acacia', 'leaf'], 0],\n",
       "  [['acacia', 'live'], 0],\n",
       "  [['acacia', 'manuscript'], 0],\n",
       "  [['acacia', 'mezzo-soprano'], 0],\n",
       "  [['acacia', 'moor'], 0],\n",
       "  [['acacia', 'pine'], 0],\n",
       "  [['acacia', 'plant'], 1],\n",
       "  [['acacia', 'poplar'], 0],\n",
       "  [['acacia', 're'], 0],\n",
       "  [['acacia', 'root'], 0],\n",
       "  [['acacia', 'spike'], 0],\n",
       "  [['acacia', 'stump'], 0],\n",
       "  [['acacia', 'treetop'], 0],\n",
       "  [['access', 'treatment'], 0],\n",
       "  [['accident', 'damage'], 1],\n",
       "  [['accident', 'flemming'], 0],\n",
       "  [['achlorhydria', 'hemolysis'], 0],\n",
       "  [['achlorhydria', 'iron'], 0],\n",
       "  [['achlorhydria', 'leukemia'], 0],\n",
       "  [['achlorhydria', 'purpura'], 0],\n",
       "  [['achlorhydria', 'thalassemia'], 0],\n",
       "  [['achlorhydria', 'transfusion'], 0],\n",
       "  [['achlorhydria', 'ulcer'], 0],\n",
       "  [['acid', 'anticoagulant'], 0],\n",
       "  [['acid', 'warfarin'], 0],\n",
       "  [['acidosis', 'death'], 0],\n",
       "  [['acidosis', 'fever'], 0],\n",
       "  [['acne', 'adolescence'], 0],\n",
       "  [['acne', 'aggression'], 0],\n",
       "  [['acne', 'bacteremia'], 0],\n",
       "  [['acne', 'bacteriuria'], 0],\n",
       "  [['acne', 'bronchitis'], 0],\n",
       "  [['acne', 'cholangitis'], 0],\n",
       "  [['acne', 'cold'], 0],\n",
       "  [['acne', 'conjunctivitis'], 0],\n",
       "  [['acne', 'dacryocystitis'], 0],\n",
       "  [['acne', 'dermatitis'], 0],\n",
       "  [['acne', 'empyema'], 0],\n",
       "  [['acne', 'fever'], 0],\n",
       "  [['acne', 'furunculosis'], 0],\n",
       "  [['acne', 'gastroenteritis'], 0],\n",
       "  [['acne', 'gonorrhea'], 0],\n",
       "  [['acne', 'hepatitis'], 0],\n",
       "  [['acne', 'hyperplasia'], 0],\n",
       "  [['acne', 'hypertrophy'], 0],\n",
       "  [['acne', 'masculinization'], 0],\n",
       "  [['acne', 'organism'], 0],\n",
       "  [['acne', 'pathogen'], 0],\n",
       "  [['acne', 'prostatitis'], 0],\n",
       "  [['acne', 'std'], 0],\n",
       "  [['acne', 'surgery'], 0],\n",
       "  [['acne', 'ulcer'], 0],\n",
       "  [['acquittal', 'ruling'], 1],\n",
       "  [['active', 'tired'], 0],\n",
       "  [['actor', 'audition'], 0],\n",
       "  [['adhesiveness', 'fever'], 0],\n",
       "  [['adhesiveness', 'headache'], 0],\n",
       "  [['adhesiveness', 'pain'], 0],\n",
       "  [['adjective', 'document'], 0],\n",
       "  [['adjective', 'word'], 1],\n",
       "  [['adolescence', 'acne'], 0],\n",
       "  [['adolescent', 'face'], 0],\n",
       "  [['adolescent', 'teen'], 1],\n",
       "  [['adrenaline', 'integer'], 0],\n",
       "  [['adrenaline', 'neurotransmitter'], 1],\n",
       "  [['adult', 'librarian'], 0],\n",
       "  [['advice', 'argument'], 0],\n",
       "  [['advice', 'treatment'], 0],\n",
       "  [['affection', 'feeling'], 1],\n",
       "  [['affection', 'organization'], 0],\n",
       "  [['affidavit', 'document'], 1],\n",
       "  [['aggression', 'acne'], 0],\n",
       "  [['aggression', 'aggressiveness'], 1],\n",
       "  [['aggression', 'hyperplasia'], 0],\n",
       "  [['aggression', 'hypertrophy'], 0],\n",
       "  [['aggression', 'libido'], 0],\n",
       "  [['aggression', 'masculinization'], 0],\n",
       "  [['aggression', 'neuron'], 1],\n",
       "  [['aggression', 'war'], 1],\n",
       "  [['aggressiveness', 'aggression'], 1],\n",
       "  [['agony', 'adult'], 0],\n",
       "  [['agony', 'decoration'], 0],\n",
       "  [['agony', 'feeling'], 1],\n",
       "  [['agreement', 'bill'], 0],\n",
       "  [['aid', 'death'], 0],\n",
       "  [['aid', 'lysis'], 0],\n",
       "  [['aid', 'treatment'], 1],\n",
       "  [['aircrew', 'playlist'], 0],\n",
       "  [['airport', 'complex'], 1],\n",
       "  [['airport', 'terminal'], 1],\n",
       "  [['alcohol', 'abscess'], 0],\n",
       "  [['alcohol', 'aneurysm'], 0],\n",
       "  [['alcohol', 'antidepressant'], 0],\n",
       "  [['alcohol', 'aspirin'], 0],\n",
       "  [['alcohol', 'buprenorphine'], 0],\n",
       "  [['alcohol', 'catarrh'], 0],\n",
       "  [['alcohol', 'cathartic'], 0],\n",
       "  [['alcohol', 'contraction'], 0],\n",
       "  [['alcohol', 'corticosteroid'], 0],\n",
       "  [['alcohol', 'cortisol'], 0],\n",
       "  [['alcohol', 'decongestant'], 0],\n",
       "  [['alcohol', 'diarrhoea'], 0],\n",
       "  [['alcohol', 'diuretic'], 0],\n",
       "  [['alcohol', 'excitement'], 0],\n",
       "  [['alcohol', 'exertion'], 0],\n",
       "  [['alcohol', 'fentanyl'], 0],\n",
       "  [['alcohol', 'fever'], 0],\n",
       "  [['alcohol', 'haemorrhage'], 0],\n",
       "  [['alcohol', 'hematoma'], 0],\n",
       "  [['alcohol', 'hotel'], 0],\n",
       "  [['alcohol', 'hypertension'], 0],\n",
       "  [['alcohol', 'hypnosis'], 0],\n",
       "  [['alcohol', 'indomethacin'], 0],\n",
       "  [['alcohol', 'ingestion'], 0],\n",
       "  [['alcohol', 'injury'], 0],\n",
       "  [['alcohol', 'laxative'], 0],\n",
       "  [['alcohol', 'lesion'], 0],\n",
       "  [['alcohol', 'liqueur'], 0],\n",
       "  [['alcohol', 'migraine'], 0],\n",
       "  [['alcohol', 'morphine'], 0],\n",
       "  [['alcohol', 'nsaid'], 0],\n",
       "  [['alcohol', 'opiate'], 0],\n",
       "  [['alcohol', 'opioids'], 0],\n",
       "  [['alcohol', 'pain'], 0],\n",
       "  [['alcohol', 'paracetamol'], 0],\n",
       "  [['alcohol', 'party'], 0],\n",
       "  [['alcohol', 'pentazocine'], 0],\n",
       "  [['alcohol', 'phenacetin'], 0],\n",
       "  [['alcohol', 'rest'], 0],\n",
       "  [['alcohol', 'salicylate'], 0],\n",
       "  [['alcohol', 'sinusitis'], 0],\n",
       "  [['alcohol', 'strain'], 0],\n",
       "  [['alcohol', 'sweating'], 0],\n",
       "  [['alcohol', 'symptom'], 0],\n",
       "  [['alcohol', 'vomiting'], 0],\n",
       "  [['alcohol', 'withdrawal'], 0],\n",
       "  [['alcoholic', 'fever'], 0],\n",
       "  [['alcoholic', 'lung'], 0],\n",
       "  [['alertness', 'arousal'], 1],\n",
       "  [['alertness', 'circulation'], 0],\n",
       "  [['alertness', 'endurance'], 0],\n",
       "  [['alertness', 'responsiveness'], 1],\n",
       "  [['alertness', 'stimulation'], 1],\n",
       "  [['alertness', 'symptom'], 0],\n",
       "  [['alive', 'destroy'], 0],\n",
       "  [['alkaloid', 'antidepressant'], 0],\n",
       "  [['alkaloid', 'aspirin'], 0],\n",
       "  [['alkaloid', 'morphine'], 0],\n",
       "  [['alkaloid', 'nsaid'], 0],\n",
       "  [['alkaloid', 'opiate'], 0],\n",
       "  [['alkaloid', 'opioids'], 0],\n",
       "  [['alkaloid', 'paracetamol'], 0],\n",
       "  [['alkaloid', 'propoxyphene'], 0],\n",
       "  [['alkaloid', 'salicylate'], 0],\n",
       "  [['allegation', 'abuse'], 0],\n",
       "  [['allergy', 'anaphylaxis'], 0],\n",
       "  [['allergy', 'asthma'], 0],\n",
       "  [['allergy', 'breathing'], 1],\n",
       "  [['allergy', 'conjunctivitis'], 0],\n",
       "  [['allergy', 'food'], 0],\n",
       "  [['allergy', 'rhinitis'], 0],\n",
       "  [['allergy', 'symptom'], 0],\n",
       "  [['allergy', 'urticaria'], 0],\n",
       "  [['alligator', 'addition'], 0],\n",
       "  [['alligator', 'alternative'], 0],\n",
       "  [['alligator', 'animal'], 1],\n",
       "  [['alligator', 'answer'], 0],\n",
       "  [['alligator', 'arrears'], 0],\n",
       "  [['alligator', 'beast'], 1],\n",
       "  [['alligator', 'contestant'], 0],\n",
       "  [['alligator', 'continent'], 0],\n",
       "  [['alligator', 'courthouse'], 0],\n",
       "  [['alligator', 'creature'], 1],\n",
       "  [['alligator', 'crocodile'], 0],\n",
       "  [['alligator', 'dock'], 0],\n",
       "  [['alligator', 'jaw'], 0],\n",
       "  [['alligator', 'leg'], 0],\n",
       "  [['alligator', 'lizard'], 0],\n",
       "  [['alligator', 'message'], 0],\n",
       "  [['alligator', 'methyl'], 0],\n",
       "  [['alligator', 'mouth'], 0],\n",
       "  [['alligator', 'rectifier'], 0],\n",
       "  [['alligator', 'skin'], 0],\n",
       "  [['alligator', 'snake'], 0],\n",
       "  [['alligator', 'st'], 0],\n",
       "  [['alligator', 'tail'], 0],\n",
       "  [['alligator', 'tooth'], 0],\n",
       "  [['alligator', 'trombone'], 0],\n",
       "  [['alligator', 'vertebrate'], 1],\n",
       "  [['alligator', 'vitro'], 0],\n",
       "  [['alopecia', 'gumma'], 0],\n",
       "  [['alopecia', 'lesion'], 0],\n",
       "  [['alopecia', 'pain'], 0],\n",
       "  [['alopecia', 'palsy'], 0],\n",
       "  [['alopecia', 'retinitis'], 0],\n",
       "  [['alopecia', 'ulcer'], 0],\n",
       "  [['alpha', 'symbol'], 1],\n",
       "  [['amblyopia', 'hemiplegia'], 0],\n",
       "  [['amblyopia', 'lightheadedness'], 0],\n",
       "  [['amblyopia', 'palsy'], 0],\n",
       "  [['ambulance', 'Saxon'], 0],\n",
       "  [['ambulance', 'T'], 0],\n",
       "  [['ambulance', 'ag'], 0],\n",
       "  [['ambulance', 'air'], 0],\n",
       "  [['ambulance', 'aqueduct'], 0],\n",
       "  [['ambulance', 'artefact'], 1],\n",
       "  [['ambulance', 'back'], 0],\n",
       "  [['ambulance', 'bicycle'], 0],\n",
       "  [['ambulance', 'bookstore'], 0],\n",
       "  [['ambulance', 'caregiver'], 0],\n",
       "  [['ambulance', 'clue'], 0],\n",
       "  [['ambulance', 'compartment'], 0],\n",
       "  [['ambulance', 'concentration'], 0],\n",
       "  [['ambulance', 'constituent'], 0],\n",
       "  [['ambulance', 'conveyance'], 1],\n",
       "  [['ambulance', 'core'], 0],\n",
       "  [['ambulance', 'crown'], 0],\n",
       "  [['ambulance', 'denial'], 0],\n",
       "  [['ambulance', 'driver'], 0],\n",
       "  [['ambulance', 'education'], 0],\n",
       "  [['ambulance', 'elasticity'], 0],\n",
       "  [['ambulance', 'engine'], 0],\n",
       "  [['ambulance', 'existance'], 0],\n",
       "  [['ambulance', 'fender'], 0],\n",
       "  [['ambulance', 'fighter'], 0],\n",
       "  [['ambulance', 'front'], 0],\n",
       "  [['ambulance', 'fuel'], 0],\n",
       "  [['ambulance', 'furlong'], 0],\n",
       "  [['ambulance', 'furnishing'], 0],\n",
       "  [['ambulance', 'gap'], 0],\n",
       "  [['ambulance', 'gas'], 0],\n",
       "  [['ambulance', 'gear'], 0],\n",
       "  [['ambulance', 'grill'], 0],\n",
       "  [['ambulance', 'gymnasium'], 0],\n",
       "  [['ambulance', 'idiophreak'], 0],\n",
       "  [['ambulance', 'inside'], 0],\n",
       "  [['ambulance', 'jet'], 0],\n",
       "  [['ambulance', 'marketer'], 0],\n",
       "  [['ambulance', 'mayor'], 0],\n",
       "  [['ambulance', 'meadow'], 0],\n",
       "  [['ambulance', 'medic'], 0],\n",
       "  [['ambulance', 'metal'], 0],\n",
       "  [['ambulance', 'mirror'], 0],\n",
       "  [['ambulance', 'motorbike'], 0],\n",
       "  [['ambulance', 'motorcycle'], 0],\n",
       "  [['ambulance', 'oil'], 0],\n",
       "  [['ambulance', 'passenger'], 0],\n",
       "  [['ambulance', 'physical'], 0],\n",
       "  [['ambulance', 'plate'], 0],\n",
       "  [['ambulance', 'pottery'], 0],\n",
       "  [['ambulance', 'pricing'], 0],\n",
       "  [['ambulance', 'radiator'], 0],\n",
       "  [['ambulance', 'rockabilly'], 0],\n",
       "  [['ambulance', 'runner-up'], 0],\n",
       "  [['ambulance', 'sauna'], 0],\n",
       "  [['ambulance', 'siren'], 0],\n",
       "  [['ambulance', 'spectrometer'], 0],\n",
       "  [['ambulance', 'statue'], 0],\n",
       "  [['ambulance', 'supplier'], 0],\n",
       "  [['ambulance', 'testing'], 0],\n",
       "  [['ambulance', 'theology'], 0],\n",
       "  [['ambulance', 'tire'], 0],\n",
       "  [['ambulance', 'tooth'], 0],\n",
       "  [['ambulance', 'top'], 0],\n",
       "  [['ambulance', 'trademark'], 0],\n",
       "  [['ambulance', 'train'], 0],\n",
       "  [['ambulance', 'truck'], 0],\n",
       "  [['ambulance', 'van'], 0],\n",
       "  [['ambulance', 'wasp'], 0],\n",
       "  [['ambulance', 'web'], 0],\n",
       "  [['ambulance', 'wheel'], 0],\n",
       "  [['ambulance', 'windscreen'], 0],\n",
       "  [['ambulance', 'windshield'], 0],\n",
       "  [['ambulance', 'yacht'], 0],\n",
       "  [['ambulance', 'yourselves'], 0],\n",
       "  [['aminoglycoside', 'chloramphenicol'], 0],\n",
       "  [['aminoglycoside', 'probenecid'], 0],\n",
       "  [['aminoglycoside', 'procaine'], 0],\n",
       "  [['aminoglycoside', 'streptomycin'], 0],\n",
       "  [['amitriptyline', 'aspirin'], 0],\n",
       "  [['amitriptyline', 'rest'], 0],\n",
       "  [['amoxicillin', 'ampicillin'], 1],\n",
       "  [['amoxicillin', 'chloramphenicol'], 0],\n",
       "  [['amoxicillin', 'ciprofloxacin'], 0],\n",
       "  [['amoxicillin', 'fluoroquinolones'], 0],\n",
       "  [['amoxicillin', 'streptomycin'], 0],\n",
       "  [['ampicillin', 'amoxicillin'], 1],\n",
       "  [['ampicillin', 'antibiotic'], 1],\n",
       "  [['ampicillin', 'chloramphenicol'], 0],\n",
       "  [['ampicillin', 'ciprofloxacin'], 0],\n",
       "  [['ampicillin', 'drug'], 1],\n",
       "  [['ampicillin', 'fluoroquinolones'], 0],\n",
       "  [['ampicillin', 'streptomycin'], 0],\n",
       "  [['ampicillin', 'vancomycin'], 0],\n",
       "  [['anaemia', 'abortion'], 0],\n",
       "  [['anaemia', 'headache'], 0],\n",
       "  [['anaemia', 'lesion'], 0],\n",
       "  [['anaemia', 'paralysis'], 0],\n",
       "  [['anaemia', 'rickets'], 0],\n",
       "  [['anaemia', 'ulcer'], 0],\n",
       "  [['analgesia', 'fever'], 0],\n",
       "  [['analgesia', 'headache'], 0],\n",
       "  [['analgesia', 'pain'], 1],\n",
       "  [['analgesia', 'sedation'], 0],\n",
       "  [['anaphylaxis', 'allergy'], 1],\n",
       "  [['anaphylaxis', 'antihistamine'], 0],\n",
       "  [['anaphylaxis', 'conjunctivitis'], 0],\n",
       "  [['anaphylaxis', 'rhinitis'], 0],\n",
       "  [['anaphylaxis', 'symptom'], 0],\n",
       "  [['anaphylaxis', 'urticaria'], 0],\n",
       "  [['anatomy', 'bodies'], 1],\n",
       "  [['ancient', 'modern'], 0],\n",
       "  [['aneurysm', 'abortion'], 0],\n",
       "  [['aneurysm', 'abscess'], 0],\n",
       "  [['aneurysm', 'alcohol'], 0],\n",
       "  [['aneurysm', 'blindness'], 0],\n",
       "  [['aneurysm', 'catarrh'], 0],\n",
       "  [['aneurysm', 'contraction'], 0],\n",
       "  [['aneurysm', 'deafness'], 0],\n",
       "  [['aneurysm', 'death'], 0],\n",
       "  [['aneurysm', 'disorder'], 1],\n",
       "  [['aneurysm', 'exertion'], 0],\n",
       "  [['aneurysm', 'fever'], 0],\n",
       "  [['aneurysm', 'haemorrhage'], 0],\n",
       "  [['aneurysm', 'headache'], 0],\n",
       "  [['aneurysm', 'hematoma'], 0],\n",
       "  [['aneurysm', 'hemiplegia'], 0],\n",
       "  [['aneurysm', 'hypertension'], 0],\n",
       "  [['aneurysm', 'ingestion'], 0],\n",
       "  [['aneurysm', 'injury'], 0],\n",
       "  [['aneurysm', 'intoxication'], 0],\n",
       "  [['aneurysm', 'lesion'], 0],\n",
       "  [['aneurysm', 'migraine'], 0],\n",
       "  [['aneurysm', 'pain'], 0],\n",
       "  [['aneurysm', 'palsy'], 0],\n",
       "  [['aneurysm', 'paralysis'], 0],\n",
       "  [['aneurysm', 'sinusitis'], 0],\n",
       "  [['aneurysm', 'sore'], 0],\n",
       "  [['aneurysm', 'stenosis'], 0],\n",
       "  [['aneurysm', 'sterility'], 0],\n",
       "  [['aneurysm', 'strain'], 0],\n",
       "  [['aneurysm', 'symptom'], 0],\n",
       "  [['aneurysm', 'ulcer'], 0],\n",
       "  [['aneurysm', 'vomiting'], 0],\n",
       "  [['anger', 'feeling'], 1],\n",
       "  [['anger', 'lizard'], 0],\n",
       "  [['anger', 'snarl'], 0],\n",
       "  [['anger', 'war'], 0],\n",
       "  [['anger', 'yell'], 0],\n",
       "  [['angioplasty', 'treatment'], 0],\n",
       "  [['angry', 'confront'], 0],\n",
       "  [['angry', 'furious'], 1],\n",
       "  [['animal', 'affidavit'], 0],\n",
       "  [['animal', 'artillery'], 0],\n",
       "  [['animal', 'bite'], 0],\n",
       "  [['animal', 'bug'], 0],\n",
       "  [['animal', 'bunny'], 0],\n",
       "  [['animal', 'cat'], 0],\n",
       "  [['animal', 'cattle'], 0],\n",
       "  [['animal', 'chick'], 0],\n",
       "  [['animal', 'crow'], 0],\n",
       "  [['animal', 'dog'], 0],\n",
       "  [['animal', 'feeder'], 0],\n",
       "  [['animal', 'furniture'], 0],\n",
       "  [['animal', 'kangaroo'], 0],\n",
       "  [['animal', 'kestrel'], 0],\n",
       "  [['animal', 'kickoff'], 0],\n",
       "  [['animal', 'lamb'], 0],\n",
       "  [['animal', 'magpie'], 0],\n",
       "  [['animal', 'organization'], 0],\n",
       "  [['animal', 'person'], 0],\n",
       "  [['animal', 'pig'], 0],\n",
       "  [['animal', 'psychotherapy'], 0],\n",
       "  [['animal', 'raccoon'], 0],\n",
       "  [['animal', 'rat'], 0],\n",
       "  [['animal', 'receptionist'], 0],\n",
       "  [['animal', 'reindeer'], 0],\n",
       "  [['animal', 'rodent'], 0],\n",
       "  [['animal', 'skunk'], 0],\n",
       "  [['animal', 'snake'], 0],\n",
       "  [['animal', 'squirrel'], 0],\n",
       "  [['animal', 'vertebrate'], 0],\n",
       "  [['animal', 'vet'], 0],\n",
       "  [['animosity', 'feeling'], 1],\n",
       "  [['animosity', 'gap'], 0],\n",
       "  [['anorexia', 'disorder'], 1],\n",
       "  [['ant', 'animal'], 1],\n",
       "  [['ant', 'antenna'], 0],\n",
       "  [['ant', 'beetle'], 0],\n",
       "  [['ant', 'bug'], 1],\n",
       "  [['ant', 'burn'], 0],\n",
       "  [['ant', 'butterfly'], 0],\n",
       "  [['ant', 'cockroach'], 0],\n",
       "  [['ant', 'coffee-table'], 0],\n",
       "  [['ant', 'creature'], 1],\n",
       "  [['ant', 'director'], 0],\n",
       "  [['ant', 'exoskeleton'], 0],\n",
       "  [['ant', 'head'], 0],\n",
       "  [['ant', 'hornet'], 0],\n",
       "  [['ant', 'humanist'], 0],\n",
       "  [['ant', 'leg'], 0],\n",
       "  [['ant', 'loop'], 0],\n",
       "  [['ant', 'mosquito'], 0],\n",
       "  [['ant', 'moth'], 0],\n",
       "  [['ant', 'overpass'], 0],\n",
       "  [['ant', 'plagiarism'], 0],\n",
       "  [['ant', 'riser'], 0],\n",
       "  [['ant', 'schema'], 0],\n",
       "  [['ant', 'theorem'], 0],\n",
       "  [['ant', 'wasp'], 0],\n",
       "  [['antheridium', 'division'], 0],\n",
       "  [['antheridium', 'gametophyte'], 0],\n",
       "  [['antheridium', 'semen'], 0],\n",
       "  [['antheridium', 'spermatogonium'], 0],\n",
       "  [['antheridium', 'testis'], 0],\n",
       "  [['anthrax', 'abscess'], 0],\n",
       "  [['anthrax', 'bite'], 0],\n",
       "  [['anthrax', 'cervicitis'], 0],\n",
       "  [['anthrax', 'gonorrhea'], 0],\n",
       "  [['anthropology', 'humans'], 1],\n",
       "  [['antibiotic', 'ampicillin'], 0],\n",
       "  [['antibiotic', 'argument'], 0],\n",
       "  [['antibiotic', 'drainage'], 0],\n",
       "  [['antibiotic', 'drug'], 1],\n",
       "  [['antibiotic', 'isotretinoin'], 0],\n",
       "  [['antibiotic', 'medication'], 1],\n",
       "  [['antibiotic', 'nsaid'], 0],\n",
       "  [['antibiotic', 'salicylate'], 0],\n",
       "  [['antibiotic', 'vancomycin'], 0],\n",
       "  [['anticoagulant', 'acid'], 0],\n",
       "  [['anticoagulant', 'warfarin'], 0],\n",
       "  [['antidepressant', 'alcohol'], 0],\n",
       "  [['antidepressant', 'alkaloid'], 0],\n",
       "  [['antidepressant', 'aspirin'], 0],\n",
       "  [['antidepressant', 'buprenorphine'], 0],\n",
       "  [['antidepressant', 'fentanyl'], 0],\n",
       "  [['antidepressant', 'hypnosis'], 0],\n",
       "  [['antidepressant', 'indomethacin'], 0],\n",
       "  [['antidepressant', 'morphine'], 0],\n",
       "  [['antidepressant', 'nsaid'], 0],\n",
       "  [['antidepressant', 'opiate'], 0],\n",
       "  [['antidepressant', 'opioids'], 0],\n",
       "  [['antidepressant', 'paracetamol'], 0],\n",
       "  [['antidepressant', 'pentazocine'], 0],\n",
       "  [['antidepressant', 'phenacetin'], 0],\n",
       "  [['antidepressant', 'propoxyphene'], 0],\n",
       "  [['antidepressant', 'salicylate'], 0],\n",
       "  [['antiemetic', 'drug'], 1],\n",
       "  [['antiemetic', 'medication'], 1],\n",
       "  [['antiemetic', 'sedative'], 0],\n",
       "  [['antihistamine', 'anaphylaxis'], 0],\n",
       "  [['antiquity', 'era'], 1],\n",
       "  [['aorta', 'artery'], 1],\n",
       "  [['aorta', 'bone'], 0],\n",
       "  [['aorta', 'brain'], 0],\n",
       "  [['aorta', 'fetus'], 0],\n",
       "  [['aorta', 'nerve'], 0],\n",
       "  [['aorta', 'placenta'], 0],\n",
       "  [['aorta', 'testis'], 0],\n",
       "  [['aorta', 'vessel'], 1],\n",
       "  [['apathy', 'feeling'], 1],\n",
       "  [['apathy', 'magnitude'], 0],\n",
       "  [['ape', 'animal'], 1],\n",
       "  [['appeal', 'argument'], 0],\n",
       "  [['appeal', 'ruling'], 1],\n",
       "  [['application', 'bill'], 0],\n",
       "  [['apprehension', 'offspring'], 0],\n",
       "  [['arbitrage', 'gap'], 0],\n",
       "  [['archbishop', 'clergyman'], 1],\n",
       "  [['archegonium', 'cervix'], 0],\n",
       "  [['archegonium', 'mucus'], 0],\n",
       "  [['archegonium', 'urethra'], 0],\n",
       "  [['archegonium', 'uterus'], 0],\n",
       "  [['argument', 'advice'], 0],\n",
       "  [['argument', 'antibiotic'], 0],\n",
       "  [['argument', 'appeal'], 0],\n",
       "  [['argument', 'claim'], 1],\n",
       "  [['argument', 'complaint'], 1],\n",
       "  [['argument', 'concensus'], 0],\n",
       "  [['argument', 'contempt'], 0],\n",
       "  [['argument', 'controversy'], 1],\n",
       "  [['argument', 'defendant'], 0],\n",
       "  [['argument', 'determination'], 0],\n",
       "  [['argument', 'distinction'], 1],\n",
       "  [['argument', 'evidence'], 1],\n",
       "  [['argument', 'expectation'], 0],\n",
       "  [['argument', 'flexibility'], 0],\n",
       "  [['argument', 'foundation'], 0],\n",
       "  [['argument', 'framework'], 0],\n",
       "  [['argument', 'ideology'], 0],\n",
       "  [['argument', 'inconsistency'], 0],\n",
       "  [['argument', 'judge'], 0],\n",
       "  [['argument', 'lawsuit'], 1],\n",
       "  [['argument', 'misgiving'], 0],\n",
       "  [['argument', 'motion'], 0],\n",
       "  [['argument', 'notice'], 0],\n",
       "  [['argument', 'odds'], 0],\n",
       "  [['argument', 'passage'], 0],\n",
       "  [['argument', 'pledge'], 0],\n",
       "  [['argument', 'presence'], 0],\n",
       "  [['argument', 'promise'], 0],\n",
       "  [['argument', 'prospectus'], 0],\n",
       "  [['argument', 'ramification'], 0],\n",
       "  [['argument', 'reassessment'], 0],\n",
       "  [['argument', 'room'], 0],\n",
       "  [['argument', 'scope'], 0],\n",
       "  [['argument', 'showing'], 0],\n",
       "  [['argument', 'skirmish'], 1],\n",
       "  [['argument', 'testimony'], 1],\n",
       "  [['argument', 'theory'], 1],\n",
       "  [['argument', 'uncertainty'], 0],\n",
       "  [['argument', 'verdict'], 0],\n",
       "  [['argument', 'wrangle'], 1],\n",
       "  [['armament', 'cannon'], 0],\n",
       "  [['army', 'organization'], 1],\n",
       "  [['army', 'soldier'], 1],\n",
       "  [['army', 'war'], 0],\n",
       "  [['arousal', 'alertness'], 0],\n",
       "  [['arousal', 'circulation'], 0],\n",
       "  [['arousal', 'endurance'], 0],\n",
       "  [['arousal', 'stimulation'], 1],\n",
       "  [['arrhythmia', 'headache'], 0],\n",
       "  [['arrhythmia', 'heartbeat'], 1],\n",
       "  [['arrhythmia', 'nervousness'], 0],\n",
       "  [['arrhythmia', 'sleeplessness'], 0],\n",
       "  [['arrhythmia', 'tachycardia'], 0],\n",
       "  [['arsenal', 'weapons'], 1],\n",
       "  [['arteriole', 'vessel'], 1],\n",
       "  [['artery', 'aorta'], 0],\n",
       "  [['artery', 'bone'], 0],\n",
       "  [['artery', 'vessel'], 1],\n",
       "  [['arthropathy', 'fever'], 0],\n",
       "  [['arthropathy', 'lesion'], 0],\n",
       "  [['article', 'ruling'], 0],\n",
       "  [['artillery', 'armament'], 1],\n",
       "  [['artillery', 'cannon'], 0],\n",
       "  [['artwork', 'integer'], 0],\n",
       "  [['artwork', 'replica'], 0],\n",
       "  [['aspirin', 'alcohol'], 0],\n",
       "  [['aspirin', 'alkaloid'], 0],\n",
       "  [['aspirin', 'amitriptyline'], 0],\n",
       "  [['aspirin', 'antidepressant'], 0],\n",
       "  [['aspirin', 'buprenorphine'], 0],\n",
       "  [['aspirin', 'drug'], 1],\n",
       "  [['aspirin', 'fentanyl'], 0],\n",
       "  [['aspirin', 'healing'], 1],\n",
       "  [['aspirin', 'hypnosis'], 0],\n",
       "  [['aspirin', 'indomethacin'], 0],\n",
       "  [['aspirin', 'morphine'], 0],\n",
       "  [['aspirin', 'nsaid'], 1],\n",
       "  [['aspirin', 'opiate'], 0],\n",
       "  [['aspirin', 'opioids'], 0],\n",
       "  [['aspirin', 'paracetamol'], 0],\n",
       "  [['aspirin', 'pentazocine'], 0],\n",
       "  [['aspirin', 'phenacetin'], 0],\n",
       "  [['aspirin', 'propoxyphene'], 0],\n",
       "  [['aspirin', 'rest'], 0],\n",
       "  [['aspirin', 'salicylate'], 1],\n",
       "  [['aspirin', 'vomiting'], 0],\n",
       "  [['aspirin', 'water'], 0],\n",
       "  [['assistance', 'treatment'], 1],\n",
       "  [['asthma', 'allergy'], 0],\n",
       "  [['asthma', 'hepatotoxicity'], 0],\n",
       "  [['asthma', 'hypoprothrombinemia'], 0],\n",
       "  [['asthma', 'pain'], 0],\n",
       "  [['asthma', 'rhinitis'], 0],\n",
       "  [['asthma', 'sedation'], 0],\n",
       "  [['asthma', 'symptom'], 0],\n",
       "  [['asthma', 'tissue'], 0],\n",
       "  [['asthma', 'toxicity'], 0],\n",
       "  [['asthma', 'ulcer'], 0],\n",
       "  [['asthma', 'urticaria'], 0],\n",
       "  [['astronomy', 'science'], 1],\n",
       "  [['atheist', 'worship'], 0],\n",
       "  [['atmosphere', 'gas'], 1],\n",
       "  [['attorney', 'professional'], 1],\n",
       "  [['audition', 'actor'], 1],\n",
       "  [['aura', 'chill'], 0],\n",
       "  [['aura', 'coughing'], 0],\n",
       "  [['aura', 'dysmenorrhea'], 0],\n",
       "  [['aura', 'headache'], 0],\n",
       "  [['aura', 'injury'], 0],\n",
       "  [['aura', 'intoxication'], 0],\n",
       "  [['aura', 'pain'], 0],\n",
       "  [['aura', 'prodrome'], 0],\n",
       "  [['aura', 'symptom'], 0],\n",
       "  [['automation', 'treatment'], 0],\n",
       "  [['axe', 'accession'], 0],\n",
       "  [['axe', 'artefact'], 1],\n",
       "  [['axe', 'blade'], 0],\n",
       "  [['axe', 'cashier'], 0],\n",
       "  [['axe', 'chmod'], 0],\n",
       "  [['axe', 'clearance'], 0],\n",
       "  [['axe', 'coast'], 0],\n",
       "  [['axe', 'consulting'], 0],\n",
       "  [['axe', 'critic'], 0],\n",
       "  [['axe', 'cutlery'], 1],\n",
       "  [['axe', 'dagger'], 0],\n",
       "  [['axe', 'edge'], 0],\n",
       "  [['axe', 'fork'], 0],\n",
       "  [['axe', 'hairbrush'], 0],\n",
       "  [['axe', 'half-back'], 0],\n",
       "  [['axe', 'handle'], 0],\n",
       "  [['axe', 'hatchet'], 0],\n",
       "  [['axe', 'head'], 0],\n",
       "  [['axe', 'implement'], 1],\n",
       "  [['axe', 'iron'], 0],\n",
       "  [['axe', 'knife'], 0],\n",
       "  [['axe', 'launcher'], 0],\n",
       "  [['axe', 'metal'], 0],\n",
       "  [['axe', 'motivation'], 0],\n",
       "  [['axe', 'ostrich'], 0],\n",
       "  [['axe', 'ovoid'], 0],\n",
       "  [['axe', 'pliers'], 0],\n",
       "  [['axe', 'popularization'], 0],\n",
       "  [['axe', 'queer'], 0],\n",
       "  [['axe', 'ringside'], 0],\n",
       "  [['axe', 'scalpel'], 0],\n",
       "  [['axe', 'sieve'], 0],\n",
       "  [['axe', 'skunk'], 0],\n",
       "  [['axe', 'sophomore'], 0],\n",
       "  [['axe', 'sustenance'], 0],\n",
       "  [['axe', 'sword'], 0],\n",
       "  [['axe', 'tool'], 1],\n",
       "  [['axe', 'tweezer'], 0],\n",
       "  [['axe', 'upholstery'], 0],\n",
       "  [['axe', 'utensil'], 1],\n",
       "  [['axe', 'wrench'], 0],\n",
       "  [['baby', 'nurse'], 0],\n",
       "  [['baby', 'offspring'], 1],\n",
       "  [['baby', 'parents'], 0],\n",
       "  [['backup', 'treatment'], 0],\n",
       "  [['bacteremia', 'abscess'], 0],\n",
       "  [['bacteremia', 'acne'], 0],\n",
       "  [['bacteremia', 'bacteriuria'], 0],\n",
       "  [['bacteremia', 'bronchitis'], 0],\n",
       "  [['bacteremia', 'chill'], 0],\n",
       "  [['bacteremia', 'cholangitis'], 0],\n",
       "  [['bacteremia', 'cold'], 0],\n",
       "  [['bacteremia', 'conjunctivitis'], 0],\n",
       "  [['bacteremia', 'dacryocystitis'], 0],\n",
       "  [['bacteremia', 'death'], 0],\n",
       "  [['bacteremia', 'dermatitis'], 0],\n",
       "  [['bacteremia', 'effusion'], 0],\n",
       "  [['bacteremia', 'empyema'], 0],\n",
       "  [['bacteremia', 'fever'], 0],\n",
       "  [['bacteremia', 'furunculosis'], 0],\n",
       "  [['bacteremia', 'gastroenteritis'], 0],\n",
       "  [['bacteremia', 'gonorrhea'], 0],\n",
       "  [['bacteremia', 'haemorrhage'], 0],\n",
       "  [['bacteremia', 'organism'], 0],\n",
       "  [['bacteremia', 'pathogen'], 0],\n",
       "  [['bacteremia', 'pleurisy'], 0],\n",
       "  [['bacteremia', 'prostatitis'], 0],\n",
       "  [['bacteremia', 'sputum'], 0],\n",
       "  [['bacteremia', 'std'], 0],\n",
       "  [['bacteremia', 'ulcer'], 0],\n",
       "  [['bacteriuria', 'acne'], 0],\n",
       "  [['bacteriuria', 'bacteremia'], 0],\n",
       "  [['bacteriuria', 'bronchitis'], 0],\n",
       "  [['bacteriuria', 'cholangitis'], 0],\n",
       "  [['bacteriuria', 'cold'], 0],\n",
       "  [['bacteriuria', 'conjunctivitis'], 0],\n",
       "  [['bacteriuria', 'dacryocystitis'], 0],\n",
       "  [['bacteriuria', 'dermatitis'], 0],\n",
       "  [['bacteriuria', 'empyema'], 0],\n",
       "  [['bacteriuria', 'fever'], 0],\n",
       "  [['bacteriuria', 'furunculosis'], 0],\n",
       "  [['bacteriuria', 'gangrene'], 0],\n",
       "  [['bacteriuria', 'gastroenteritis'], 0],\n",
       "  [['bacteriuria', 'gonorrhea'], 0],\n",
       "  [['bacteriuria', 'organism'], 0],\n",
       "  [['bacteriuria', 'pathogen'], 0],\n",
       "  [['bacteriuria', 'prostatitis'], 0],\n",
       "  [['bacteriuria', 'std'], 0],\n",
       "  [['bacteriuria', 'ulcer'], 0],\n",
       "  [['badminton', 'kettle'], 0],\n",
       "  [['badminton', 'sport'], 1],\n",
       "  [['bake', 'toast'], 0],\n",
       "  [['balance', 'gap'], 0],\n",
       "  [['balance', 'surplus'], 0],\n",
       "  [['bamboo', 'bear'], 0],\n",
       "  [['ban', 'war'], 0],\n",
       "  [['banana', 'bowel'], 0],\n",
       "  [['banana', 'coconut'], 0],\n",
       "  [['banana', 'cranberry'], 0],\n",
       "  [['banana', 'desolation'], 0],\n",
       "  [['banana', 'dustbin'], 0],\n",
       "  [['banana', 'fiber'], 0],\n",
       "  [['banana', 'food'], 1],\n",
       "  [['banana', 'grapefruit'], 0],\n",
       "  [['banana', 'groom'], 0],\n",
       "  [['banana', 'hemorrhoid'], 0],\n",
       "  [['banana', 'laxative'], 0],\n",
       "  [['banana', 'lime'], 0],\n",
       "  [['banana', 'mango'], 0],\n",
       "  [['banana', 'marking'], 0],\n",
       "  [['banana', 'masquerade'], 0],\n",
       "  [['banana', 'morphine'], 0],\n",
       "  [['banana', 'narcotic'], 0],\n",
       "  [['banana', 'opioids'], 0],\n",
       "  [['banana', 'pain'], 0],\n",
       "  [['banana', 'panelist'], 0],\n",
       "  [['banana', 'papaya'], 0],\n",
       "  [['banana', 'peach'], 0],\n",
       "  [['banana', 'pineapple'], 0],\n",
       "  [['banana', 'plum'], 0],\n",
       "  [['banana', 'potassium'], 0],\n",
       "  [['banana', 'produce'], 1],\n",
       "  [['banana', 'skin'], 0],\n",
       "  [['banana', 'sore'], 0],\n",
       "  [['banana', 'wingspan'], 0],\n",
       "  [['bank', 'loans'], 1],\n",
       "  [['bank', 'money'], 1],\n",
       "  [['bank', 'river'], 1],\n",
       "  [['barbeque', 'fire'], 0],\n",
       "  [['baronetcy', 'status'], 1],\n",
       "  [['barrier', 'fender'], 0],\n",
       "  [['barrier', 'gap'], 0],\n",
       "  [['barrier', 'psychotherapy'], 0],\n",
       "  [['baseboard', 'wall'], 1],\n",
       "  [['basil', 'herb'], 1],\n",
       "  [['basketball', 'dribbling'], 1],\n",
       "  [['basketball', 'shooting'], 1],\n",
       "  [['bathing', 'shampooing'], 1],\n",
       "  [['bathroom', 'lavatory'], 1],\n",
       "  [['baton', 'conductor'], 0],\n",
       "  [['bear', 'MP'], 0],\n",
       "  [['bear', 'ace'], 0],\n",
       "  [['bear', 'algae'], 0],\n",
       "  [['bear', 'animal'], 1],\n",
       "  [['bear', 'beast'], 1],\n",
       "  [['bear', 'beaver'], 0],\n",
       "  [['bear', 'cat'], 0],\n",
       "  [['bear', 'claw'], 0],\n",
       "  [['bear', 'co-operative'], 0],\n",
       "  [['bear', 'complaint'], 0],\n",
       "  [['bear', 'courtyard'], 0],\n",
       "  [['bear', 'cow'], 0],\n",
       "  [['bear', 'coyote'], 0],\n",
       "  [['bear', 'creature'], 1],\n",
       "  [['bear', 'deer'], 0],\n",
       "  [['bear', 'document'], 0],\n",
       "  [['bear', 'dog'], 0],\n",
       "  [['bear', 'donkey'], 0],\n",
       "  [['bear', 'drama'], 0],\n",
       "  [['bear', 'entropy'], 0],\n",
       "  [['bear', 'filling'], 0],\n",
       "  [['bear', 'fur'], 0],\n",
       "  [['bear', 'giraffe'], 0],\n",
       "  [['bear', 'goat'], 0],\n",
       "  [['bear', 'gorilla'], 0],\n",
       "  [['bear', 'head'], 0],\n",
       "  [['bear', 'jaw'], 0],\n",
       "  [['bear', 'leg'], 0],\n",
       "  [['bear', 'litter'], 0],\n",
       "  [['bear', 'magnitude'], 0],\n",
       "  [['bear', 'mouth'], 0],\n",
       "  [['bear', 'multiple'], 0],\n",
       "  [['bear', 'organisation'], 0],\n",
       "  [['bear', 'pig'], 0],\n",
       "  [['bear', 'punctuality'], 0],\n",
       "  [['bear', 'rat'], 0],\n",
       "  [['bear', 'sensor'], 0],\n",
       "  [['bear', 'snout'], 0],\n",
       "  [['bear', 'squirrel'], 0],\n",
       "  [['bear', 'toll'], 0],\n",
       "  [['bear', 'tooth'], 0],\n",
       "  [['bear', 'traitor'], 0],\n",
       "  [['bear', 'vertebrate'], 1],\n",
       "  [['bear', 'webcam'], 0],\n",
       "  [['beat', 'defeated'], 1],\n",
       "  [['beating', 'abuse'], 1],\n",
       "  [['beautiful', 'pretty'], 1],\n",
       "  [['beaver', 'amateur'], 0],\n",
       "  [['beaver', 'animal'], 1],\n",
       "  [['beaver', 'archdeaconry'], 0],\n",
       "  [['beaver', 'bear'], 0],\n",
       "  [['beaver', 'beast'], 1],\n",
       "  [['beaver', 'cat'], 0],\n",
       "  [['beaver', 'claimant'], 0],\n",
       "  [['beaver', 'coffee-table'], 0],\n",
       "  [['beaver', 'cow'], 0],\n",
       "  [['beaver', 'coyote'], 0],\n",
       "  [['beaver', 'creature'], 1],\n",
       "  [['beaver', 'deer'], 0],\n",
       "  [['beaver', 'digger'], 0],\n",
       "  [['beaver', 'dog'], 0],\n",
       "  [['beaver', 'donkey'], 0],\n",
       "  [['beaver', 'erosion'], 0],\n",
       "  [['beaver', 'fur'], 0],\n",
       "  [['beaver', 'giraffe'], 0],\n",
       "  [['beaver', 'goat'], 0],\n",
       "  [['beaver', 'gorilla'], 0],\n",
       "  [['beaver', 'head'], 0],\n",
       "  [['beaver', 'leg'], 0],\n",
       "  [['beaver', 'microprocessor'], 0],\n",
       "  [['beaver', 'mortgage'], 0],\n",
       "  [['beaver', 'mouse'], 0],\n",
       "  [['beaver', 'mouth'], 0],\n",
       "  [['beaver', 'pastime'], 0],\n",
       "  [['beaver', 'pig'], 0],\n",
       "  [['beaver', 'prescriber'], 0],\n",
       "  [['beaver', 'rat'], 0],\n",
       "  [['beaver', 'rodent'], 1],\n",
       "  [['beaver', 'section'], 0],\n",
       "  [['beaver', 'series'], 0],\n",
       "  [['beaver', 'siege'], 0],\n",
       "  [['beaver', 'snout'], 0],\n",
       "  [['beaver', 'squirrel'], 0],\n",
       "  [['beaver', 'tail'], 0],\n",
       "  [['beaver', 'test'], 0],\n",
       "  [['beaver', 'theology'], 0],\n",
       "  [['beaver', 'tooth'], 0],\n",
       "  [['beaver', 'vertebrate'], 1],\n",
       "  [['beech', 'artillery'], 0],\n",
       "  [['beer', 'beverage'], 1],\n",
       "  [['beer', 'liquid'], 1],\n",
       "  [['beet', 'aluminum'], 0],\n",
       "  [['beet', 'bean'], 0],\n",
       "  [['beet', 'bout'], 0],\n",
       "  [['beet', 'broccoli'], 0],\n",
       "  [['beet', 'cabbage'], 0],\n",
       "  [['beet', 'carrot'], 0],\n",
       "  [['beet', 'cauliflower'], 0],\n",
       "  [['beet', 'chaplain'], 0],\n",
       "  [['beet', 'clinician'], 0],\n",
       "  [['beet', 'cucumber'], 0],\n",
       "  [['beet', 'down'], 0],\n",
       "  [['beet', 'food'], 1],\n",
       "  [['beet', 'found'], 0],\n",
       "  [['beet', 'garlic'], 0],\n",
       "  [['beet', 'homology'], 0],\n",
       "  [['beet', 'hypertension'], 0],\n",
       "  [['beet', 'junior'], 0],\n",
       "  [['beet', 'leaf'], 0],\n",
       "  [['beet', 'limbo'], 0],\n",
       "  [['beet', 'mavoc'], 0],\n",
       "  [['beet', 'parsley'], 0],\n",
       "  [['beet', 'potato'], 0],\n",
       "  [['beet', 'produce'], 1],\n",
       "  [['beet', 'productivity'], 0],\n",
       "  [['beet', 'range'], 0],\n",
       "  [['beet', 'root'], 1],\n",
       "  [['beet', 'sermon'], 0],\n",
       "  [['beet', 'sister'], 0],\n",
       "  [['beet', 'spinach'], 0],\n",
       "  [['beet', 'symposium'], 0],\n",
       "  [['beet', 'twentieth-century'], 0],\n",
       "  [['beetle', 'animal'], 1],\n",
       "  [['beetle', 'ant'], 0],\n",
       "  [['beetle', 'antenna'], 0],\n",
       "  [['beetle', 'bug'], 1],\n",
       "  [['beetle', 'burst'], 0],\n",
       "  [['beetle', 'butterfly'], 0],\n",
       "  [['beetle', 'cockroach'], 0],\n",
       "  [['beetle', 'creature'], 1],\n",
       "  [['beetle', 'exoskeleton'], 0],\n",
       "  [['beetle', 'head'], 0],\n",
       "  [['beetle', 'hornet'], 0],\n",
       "  [['beetle', 'leg'], 0],\n",
       "  [['beetle', 'loom'], 0],\n",
       "  [['beetle', 'magnet'], 0],\n",
       "  [['beetle', 'mascot'], 0],\n",
       "  [['beetle', 'mosquito'], 0],\n",
       "  [['beetle', 'moth'], 0],\n",
       "  [['beetle', 'protease'], 0],\n",
       "  [['beetle', 'request'], 0],\n",
       "  [['beetle', 'room'], 0],\n",
       "  [['beetle', 'saga'], 0],\n",
       "  [['beetle', 'spectrum'], 0],\n",
       "  [['beetle', 'surprise'], 0],\n",
       "  [['beetle', 'wasp'], 0],\n",
       "  [['beetle', 'weak'], 0],\n",
       "  [['beetle', 'wing'], 0],\n",
       "  [['beg', 'request'], 1],\n",
       "  [['believe', 'faith'], 0],\n",
       "  [['benzodiazepine', 'drug'], 1],\n",
       "  [['beverage', 'beer'], 0],\n",
       "  [['beverage', 'liquid'], 1],\n",
       "  [['beverage', 'symbol'], 0],\n",
       "  [['beverage', 'water'], 0],\n",
       "  [['beverage', 'whisky'], 0],\n",
       "  [['beverages', 'sodas'], 0],\n",
       "  [['bicycle', 'wheel'], 1],\n",
       "  [['bigot', 'hateful'], 1],\n",
       "  [['bill', 'agreement'], 0],\n",
       "  [['bill', 'application'], 0],\n",
       "  [['bill', 'budget'], 0],\n",
       "  [['bill', 'document'], 1],\n",
       "  [['bill', 'draft'], 0],\n",
       "  [['bill', 'matter'], 1],\n",
       "  [['bill', 'measure'], 1],\n",
       "  [['bill', 'motion'], 1],\n",
       "  [['bill', 'pact'], 0],\n",
       "  [['bill', 'payment'], 0],\n",
       "  [['bill', 'policy'], 1],\n",
       "  [['bill', 'reform'], 0],\n",
       "  [['bill', 'regulation'], 1],\n",
       "  [['bill', 'repo'], 0],\n",
       "  [['bill', 'resolution'], 0],\n",
       "  [['bill', 'rule'], 1],\n",
       "  [['bill', 'scheme'], 1],\n",
       "  [['bill', 'settlement'], 1],\n",
       "  [['bill', 'text'], 1],\n",
       "  [['bill', 'treaty'], 0],\n",
       "  [['bin', 'mail'], 0],\n",
       "  [['birch', 'ITN'], 0],\n",
       "  [['birch', 'acacia'], 0],\n",
       "  [['birch', 'artery'], 0],\n",
       "  [['birch', 'ballast'], 0],\n",
       "  ...],\n",
       " 'assess_data': [[['abbey', 'nun'], 1],\n",
       "  [['absolve', 'sinner'], 1],\n",
       "  [['abstinence', 'anxiety'], 0],\n",
       "  [['abstinence', 'depression'], 0],\n",
       "  [['abstinence', 'stress'], 0],\n",
       "  [['acetaminophen', 'camphor'], 0],\n",
       "  [['acetaminophen', 'codeine'], 0],\n",
       "  [['acetaminophen', 'methadone'], 0],\n",
       "  [['acetaminophen', 'phenylbutazone'], 0],\n",
       "  [['acetaminophen', 'trichloroethylene'], 0],\n",
       "  [['actinomycosis', 'angina'], 0],\n",
       "  [['actinomycosis', 'cellulitis'], 0],\n",
       "  [['actinomycosis', 'meningitis'], 0],\n",
       "  [['actinomycosis', 'nephrosis'], 0],\n",
       "  [['actinomycosis', 'neurosyphilis'], 0],\n",
       "  [['actinomycosis', 'pharyngitis'], 0],\n",
       "  [['actinomycosis', 'syphilis'], 0],\n",
       "  [['actinomycosis', 'yaw'], 0],\n",
       "  [['activist', 'federation'], 0],\n",
       "  [['administration', 'government'], 1],\n",
       "  [['administration', 'management'], 1],\n",
       "  [['adorable', 'cute'], 1],\n",
       "  [['advisories', 'federation'], 0],\n",
       "  [['aerospace', 'management'], 1],\n",
       "  [['agenda', 'element'], 0],\n",
       "  [['aircraft', 'bomber'], 0],\n",
       "  [['aircraft', 'warplane'], 1],\n",
       "  [['airplane', 'bomber'], 0],\n",
       "  [['airplane', 'warplane'], 1],\n",
       "  [['ambassador', 'worker'], 1],\n",
       "  [['aminoglycosides', 'carbenicillin'], 0],\n",
       "  [['aminoglycosides', 'cephalosporin'], 0],\n",
       "  [['aminoglycosides', 'erythromycin'], 0],\n",
       "  [['aminoglycosides', 'rifampin'], 0],\n",
       "  [['aminoglycosides', 'tetracycline'], 0],\n",
       "  [['amphetamine', 'anxiety'], 0],\n",
       "  [['amphetamine', 'irritability'], 0],\n",
       "  [['analgesic', 'azathioprine'], 0],\n",
       "  [['analgesic', 'child'], 0],\n",
       "  [['analgesic', 'codeine'], 0],\n",
       "  [['analgesic', 'diet'], 0],\n",
       "  [['analgesic', 'massage'], 0],\n",
       "  [['analgesic', 'peristalsis'], 0],\n",
       "  [['analgesic', 'stress'], 0],\n",
       "  [['analgesic', 'verapamil'], 0],\n",
       "  [['ancestor', 'motto'], 0],\n",
       "  [['androgen', 'dehydroepiandrosterone'], 0],\n",
       "  [['androgen', 'diet'], 0],\n",
       "  [['androgen', 'oestradiol'], 0],\n",
       "  [['androgen', 'pregnenolone'], 0],\n",
       "  [['androgen', 'stress'], 0],\n",
       "  [['androgen', 'testosterone'], 0],\n",
       "  [['androgen', 'woman'], 0],\n",
       "  [['anemia', 'bleeding'], 0],\n",
       "  [['anemia', 'bronchospasm'], 0],\n",
       "  [['anemia', 'depression'], 0],\n",
       "  [['anemia', 'haematemesis'], 0],\n",
       "  [['anemia', 'nausea'], 0],\n",
       "  [['anemia', 'rash'], 0],\n",
       "  [['anemia', 'tenosynovitis'], 0],\n",
       "  [['angina', 'actinomycosis'], 0],\n",
       "  [['angina', 'cellulitis'], 0],\n",
       "  [['angina', 'meningitis'], 0],\n",
       "  [['angina', 'nephrosis'], 0],\n",
       "  [['angina', 'neurosyphilis'], 0],\n",
       "  [['angina', 'pharyngitis'], 0],\n",
       "  [['angina', 'syphilis'], 0],\n",
       "  [['angina', 'yaw'], 0],\n",
       "  [['angiogenesis', 'erythropoiesis'], 0],\n",
       "  [['anhydrase', 'enolase'], 0],\n",
       "  [['ankle', 'wrist'], 0],\n",
       "  [['anxiety', 'abstinence'], 0],\n",
       "  [['anxiety', 'amphetamine'], 0],\n",
       "  [['anxiety', 'arteritis'], 0],\n",
       "  [['anxiety', 'depression'], 0],\n",
       "  [['anxiety', 'dizziness'], 0],\n",
       "  [['anxiety', 'fatigue'], 0],\n",
       "  [['anxiety', 'hyperthyroidism'], 0],\n",
       "  [['anxiety', 'irritability'], 1],\n",
       "  [['anxiety', 'itching'], 0],\n",
       "  [['anxiety', 'jitteriness'], 1],\n",
       "  [['anxiety', 'meningitis'], 0],\n",
       "  [['anxiety', 'nausea'], 0],\n",
       "  [['anxiety', 'reading'], 0],\n",
       "  [['anxiety', 'stress'], 1],\n",
       "  [['anxiety', 'syphilis'], 0],\n",
       "  [['anxiety', 'tumour'], 0],\n",
       "  [['anxiety', 'vasoconstriction'], 0],\n",
       "  [['appendicitis', 'meningitis'], 0],\n",
       "  [['apples', 'fruit'], 1],\n",
       "  [['arteritis', 'anxiety'], 0],\n",
       "  [['arteritis', 'encephalopathy'], 0],\n",
       "  [['arteritis', 'hunger'], 0],\n",
       "  [['arteritis', 'hypoglycemia'], 0],\n",
       "  [['arteritis', 'meningitis'], 0],\n",
       "  [['arteritis', 'stress'], 0],\n",
       "  [['arteritis', 'syphilis'], 0],\n",
       "  [['arteritis', 'tumour'], 0],\n",
       "  [['aspect', 'element'], 1],\n",
       "  [['aspiration', 'atelectasis'], 0],\n",
       "  [['aspiration', 'bacillus'], 0],\n",
       "  [['aspiration', 'bacteria'], 0],\n",
       "  [['aspiration', 'cough'], 0],\n",
       "  [['aspiration', 'meningitis'], 0],\n",
       "  [['aspiration', 'streptococcus'], 0],\n",
       "  [['assortment', 'collection'], 1],\n",
       "  [['atelectasis', 'aspiration'], 0],\n",
       "  [['atelectasis', 'cough'], 0],\n",
       "  [['atrophy', 'chorioretinitis'], 0],\n",
       "  [['atrophy', 'insanity'], 0],\n",
       "  [['atrophy', 'neuritis'], 0],\n",
       "  [['atrophy', 'papillitis'], 0],\n",
       "  [['atrophy', 'paresis'], 1],\n",
       "  [['attack', 'strategy'], 1],\n",
       "  [['authority', 'government'], 0],\n",
       "  [['availability', 'liquidity'], 0],\n",
       "  [['azalea', 'bush'], 1],\n",
       "  [['azathioprine', 'analgesic'], 0],\n",
       "  [['bacillus', 'aspiration'], 0],\n",
       "  [['bacillus', 'bacteria'], 1],\n",
       "  [['bacillus', 'bacterium'], 1],\n",
       "  [['bacillus', 'fungi'], 0],\n",
       "  [['bacillus', 'neurotoxin'], 0],\n",
       "  [['bacillus', 'streptococcus'], 0],\n",
       "  [['bacillus', 'toxin'], 0],\n",
       "  [['bacteria', 'aspiration'], 0],\n",
       "  [['bacteria', 'bacillus'], 0],\n",
       "  [['bacteria', 'bacterium'], 1],\n",
       "  [['bacteria', 'cellulitis'], 0],\n",
       "  [['bacteria', 'diet'], 0],\n",
       "  [['bacteria', 'disease'], 1],\n",
       "  [['bacteria', 'fungi'], 0],\n",
       "  [['bacteria', 'illness'], 1],\n",
       "  [['bacteria', 'lactase'], 0],\n",
       "  [['bacteria', 'meningitis'], 0],\n",
       "  [['bacteria', 'neurotoxin'], 0],\n",
       "  [['bacteria', 'peritonitis'], 0],\n",
       "  [['bacteria', 'streptococcus'], 0],\n",
       "  [['bacteria', 'syphilis'], 0],\n",
       "  [['bacteria', 'toxin'], 0],\n",
       "  [['bacterium', 'bacillus'], 0],\n",
       "  [['bacterium', 'bacteria'], 1],\n",
       "  [['bacterium', 'neurotoxin'], 0],\n",
       "  [['bacterium', 'toxin'], 0],\n",
       "  [['bag', 'bottle'], 0],\n",
       "  [['bag', 'cent'], 0],\n",
       "  [['bag', 'circumcision'], 0],\n",
       "  [['bag', 'condition'], 0],\n",
       "  [['bag', 'content'], 0],\n",
       "  [['bag', 'key'], 0],\n",
       "  [['bag', 'luggage'], 1],\n",
       "  [['bag', 'parting'], 0],\n",
       "  [['bag', 'trunk'], 0],\n",
       "  [['bag', 'wash'], 0],\n",
       "  [['balloon', 'aircraft'], 1],\n",
       "  [['beach', 'sand'], 1],\n",
       "  [['bed', 'bookcase'], 0],\n",
       "  [['bed', 'compilation'], 0],\n",
       "  [['bed', 'promoter'], 0],\n",
       "  [['bed', 'security'], 0],\n",
       "  [['bed', 'sofa'], 0],\n",
       "  [['bed', 'wood'], 0],\n",
       "  [['bed', 'yarn'], 0],\n",
       "  [['bee', 'invertebrate'], 1],\n",
       "  [['benzene', 'hydrocarbon'], 1],\n",
       "  [['benzene', 'tent'], 0],\n",
       "  [['berry', 'fruit'], 1],\n",
       "  [['bib', 'fabric'], 1],\n",
       "  [['big', 'large'], 1],\n",
       "  [['bingo', 'game'], 1],\n",
       "  [['bird', 'lips'], 0],\n",
       "  [['bird', 'seabird'], 0],\n",
       "  [['bird', 'woman'], 0],\n",
       "  [['bitterness', 'emotion'], 1],\n",
       "  [['bleeding', 'anemia'], 0],\n",
       "  [['bleeding', 'bronchospasm'], 0],\n",
       "  [['bleeding', 'depression'], 0],\n",
       "  [['bleeding', 'diet'], 0],\n",
       "  [['bleeding', 'fatigue'], 0],\n",
       "  [['bleeding', 'haematemesis'], 0],\n",
       "  [['bleeding', 'nausea'], 0],\n",
       "  [['bleeding', 'pallor'], 0],\n",
       "  [['bleeding', 'parasite'], 0],\n",
       "  [['bleeding', 'pregnancy'], 0],\n",
       "  [['bleeding', 'tapeworm'], 0],\n",
       "  [['boat', 'ship'], 1],\n",
       "  [['bomb', 'Kalashnikov'], 0],\n",
       "  [['bomb', 'agent'], 0],\n",
       "  [['bomb', 'bow'], 0],\n",
       "  [['bomb', 'daybreak'], 0],\n",
       "  [['bomb', 'device'], 1],\n",
       "  [['bomb', 'disease'], 0],\n",
       "  [['bomb', 'droplet'], 0],\n",
       "  [['bomb', 'exam'], 0],\n",
       "  [['bomb', 'grenade'], 0],\n",
       "  [['bomb', 'kalashnikov'], 0],\n",
       "  [['bomb', 'limitation'], 0],\n",
       "  [['bomb', 'luscan'], 0],\n",
       "  [['bomb', 'meal'], 0],\n",
       "  [['bomb', 'pike'], 0],\n",
       "  [['bomb', 'revolver'], 0],\n",
       "  [['bomb', 'steel'], 0],\n",
       "  [['bomb', 'trip'], 0],\n",
       "  [['bomb', 'warplane'], 0],\n",
       "  [['bomber', 'aeroplane'], 1],\n",
       "  [['bomber', 'aircraft'], 1],\n",
       "  [['bomber', 'airplane'], 1],\n",
       "  [['bomber', 'aunt'], 0],\n",
       "  [['bomber', 'bomb'], 0],\n",
       "  [['bomber', 'brake'], 0],\n",
       "  [['bomber', 'bus'], 0],\n",
       "  [['bomber', 'captain'], 0],\n",
       "  [['bomber', 'catastrophe'], 0],\n",
       "  [['bomber', 'census'], 0],\n",
       "  [['bomber', 'craft'], 1],\n",
       "  [['bomber', 'crew'], 0],\n",
       "  [['bomber', 'finance'], 0],\n",
       "  [['bomber', 'law'], 0],\n",
       "  [['bomber', 'ownership'], 0],\n",
       "  [['bomber', 'plinth'], 0],\n",
       "  [['bomber', 'rear'], 0],\n",
       "  [['bomber', 'rocket'], 0],\n",
       "  [['bomber', 'rudder'], 0],\n",
       "  [['bomber', 'seat'], 0],\n",
       "  [['bomber', 'steel'], 0],\n",
       "  [['bomber', 'tanker'], 0],\n",
       "  [['bomber', 'tubing'], 0],\n",
       "  [['bomber', 'warplane'], 1],\n",
       "  [['bomber', 'west'], 0],\n",
       "  [['bookcase', 'balcony'], 0],\n",
       "  [['bookcase', 'bed'], 0],\n",
       "  [['bookcase', 'boxer'], 0],\n",
       "  [['bookcase', 'cash'], 0],\n",
       "  [['bookcase', 'centre'], 0],\n",
       "  [['bookcase', 'contravention'], 0],\n",
       "  [['bookcase', 'garrison'], 0],\n",
       "  [['bookcase', 'shelf'], 1],\n",
       "  [['bookcase', 'sofa'], 0],\n",
       "  [['bookcase', 'wood'], 0],\n",
       "  [['books', 'library'], 0],\n",
       "  [['bottle', 'bag'], 0],\n",
       "  [['bottle', 'cap'], 0],\n",
       "  [['bottle', 'chalice'], 0],\n",
       "  [['bottle', 'content'], 0],\n",
       "  [['bottle', 'glass'], 0],\n",
       "  [['bottle', 'label'], 0],\n",
       "  [['bottle', 'lid'], 0],\n",
       "  [['bottle', 'limitation'], 0],\n",
       "  [['bottle', 'microphone'], 0],\n",
       "  [['bottle', 'process'], 0],\n",
       "  [['bottle', 'profit'], 0],\n",
       "  [['bottle', 'rd'], 0],\n",
       "  [['bottle', 'readership'], 0],\n",
       "  [['bottle', 'summit'], 0],\n",
       "  [['bottle', 'tail-spin'], 0],\n",
       "  [['bottle', 'tumbler'], 0],\n",
       "  [['bowling', 'game'], 1],\n",
       "  [['bps', 'warplane'], 1],\n",
       "  [['breakdown', 'element'], 0],\n",
       "  [['breaker', 'worker'], 1],\n",
       "  [['bronchospasm', 'anemia'], 0],\n",
       "  [['bronchospasm', 'bleeding'], 0],\n",
       "  [['bronchospasm', 'haematemesis'], 0],\n",
       "  [['bronchospasm', 'nausea'], 0],\n",
       "  [['buffalo', 'mammal'], 1],\n",
       "  [['buggy', 'garment'], 0],\n",
       "  [['bumper', 'ding'], 0],\n",
       "  [['bunch', 'grape'], 1],\n",
       "  [['bus', 'accelerator'], 0],\n",
       "  [['bus', 'bike'], 0],\n",
       "  [['bus', 'bomber'], 0],\n",
       "  [['bus', 'brake'], 0],\n",
       "  [['bus', 'bumper'], 0],\n",
       "  [['bus', 'census'], 0],\n",
       "  [['bus', 'cheetah'], 0],\n",
       "  [['bus', 'daughter'], 0],\n",
       "  [['bus', 'field'], 0],\n",
       "  [['bus', 'flagship'], 0],\n",
       "  [['bus', 'heading'], 0],\n",
       "  [['bus', 'headlight'], 0],\n",
       "  [['bus', 'hobby'], 0],\n",
       "  [['bus', 'horn'], 0],\n",
       "  [['bus', 'immigration'], 0],\n",
       "  [['bus', 'lamp'], 0],\n",
       "  [['bus', 'library'], 0],\n",
       "  [['bus', 'magazine'], 0],\n",
       "  [['bus', 'microwave'], 0],\n",
       "  [['bus', 'moped'], 0],\n",
       "  [['bus', 'mother'], 0],\n",
       "  [['bus', 'petrol'], 0],\n",
       "  [['bus', 'radiation'], 0],\n",
       "  [['bus', 'radio'], 0],\n",
       "  [['bus', 'ragtime'], 0],\n",
       "  [['bus', 'rear'], 0],\n",
       "  [['bus', 'seat'], 0],\n",
       "  [['bus', 'seatbelt'], 0],\n",
       "  [['bus', 'steel'], 0],\n",
       "  [['bus', 'tank'], 0],\n",
       "  [['bus', 'tanker'], 0],\n",
       "  [['bus', 'telly'], 0],\n",
       "  [['bus', 'tractor'], 0],\n",
       "  [['bus', 'trunk'], 0],\n",
       "  [['bush', 'azalea'], 0],\n",
       "  [['bushes', 'trap'], 1],\n",
       "  [['calculation', 'temperature'], 0],\n",
       "  [['cameraman', 'artist'], 1],\n",
       "  [['camphor', 'acetaminophen'], 0],\n",
       "  [['camphor', 'codeine'], 0],\n",
       "  [['camphor', 'methadone'], 0],\n",
       "  [['camphor', 'phenylbutazone'], 0],\n",
       "  [['camphor', 'trichloroethylene'], 0],\n",
       "  [['cancer', 'cytotoxicity'], 0],\n",
       "  [['cancer', 'radical'], 0],\n",
       "  [['captivity', 'internment'], 0],\n",
       "  [['carbenicillin', 'aminoglycosides'], 0],\n",
       "  [['carbenicillin', 'cephalosporin'], 0],\n",
       "  [['carbenicillin', 'erythromycin'], 0],\n",
       "  [['carbenicillin', 'rifampin'], 0],\n",
       "  [['carbenicillin', 'tetracycline'], 0],\n",
       "  [['carp', 'aide'], 0],\n",
       "  [['carp', 'blight'], 0],\n",
       "  [['carp', 'chordate'], 1],\n",
       "  [['carp', 'cod'], 0],\n",
       "  [['carp', 'disease'], 0],\n",
       "  [['carp', 'eye'], 0],\n",
       "  [['carp', 'fin'], 0],\n",
       "  [['carp', 'fish'], 1],\n",
       "  [['carp', 'goldfish'], 0],\n",
       "  [['carp', 'grove'], 0],\n",
       "  [['carp', 'salmon'], 0],\n",
       "  [['carp', 'seafood'], 1],\n",
       "  [['carp', 'temperature'], 0],\n",
       "  [['carp', 'trouble'], 0],\n",
       "  [['carp', 'trout'], 0],\n",
       "  [['carp', 'whale'], 0],\n",
       "  [['carpenter', 'worker'], 1],\n",
       "  [['cars', 'racetrack'], 0],\n",
       "  [['cash', 'liquidity'], 1],\n",
       "  [['cashews', 'nuts'], 1],\n",
       "  [['cashmere', 'goods'], 1],\n",
       "  [['castigate', 'criticize'], 1],\n",
       "  [['cathedral', 'altar'], 0],\n",
       "  [['cathedral', 'amendment'], 0],\n",
       "  [['cathedral', 'arch'], 0],\n",
       "  [['cathedral', 'candle'], 0],\n",
       "  [['cathedral', 'choir'], 0],\n",
       "  [['cathedral', 'consumer'], 0],\n",
       "  [['cathedral', 'diskette'], 0],\n",
       "  [['cathedral', 'dividend'], 0],\n",
       "  [['cathedral', 'edifice'], 1],\n",
       "  [['cathedral', 'library'], 0],\n",
       "  [['cathedral', 'lottery'], 0],\n",
       "  [['cathedral', 'owner'], 0],\n",
       "  [['cathedral', 'prejudice'], 0],\n",
       "  [['cathedral', 'premise'], 0],\n",
       "  [['cathedral', 'project'], 0],\n",
       "  [['cathedral', 'pub'], 0],\n",
       "  [['cathedral', 'restaurant'], 0],\n",
       "  [['cathedral', 'result'], 0],\n",
       "  [['cathedral', 'skyscraper'], 0],\n",
       "  [['cathedral', 'strategy'], 0],\n",
       "  [['cathedral', 'synagogue'], 0],\n",
       "  [['cathedral', 'throughput'], 0],\n",
       "  [['cathedral', 'villa'], 0],\n",
       "  [['cathedral', 'vowel'], 0],\n",
       "  [['caucus', 'gathering'], 1],\n",
       "  [['cellist', 'performer'], 1],\n",
       "  [['cellulitis', 'actinomycosis'], 0],\n",
       "  [['cellulitis', 'angina'], 0],\n",
       "  [['cellulitis', 'bacteria'], 0],\n",
       "  [['cellulitis', 'disease'], 1],\n",
       "  [['cellulitis', 'illness'], 1],\n",
       "  [['cellulitis', 'meningitis'], 0],\n",
       "  [['cellulitis', 'nephrosis'], 0],\n",
       "  [['cellulitis', 'neurosyphilis'], 0],\n",
       "  [['cellulitis', 'peritonitis'], 0],\n",
       "  [['cellulitis', 'pharyngitis'], 0],\n",
       "  [['cellulitis', 'syphilis'], 0],\n",
       "  [['cellulitis', 'yaw'], 0],\n",
       "  [['cephalosporin', 'aminoglycosides'], 0],\n",
       "  [['cephalosporin', 'carbenicillin'], 0],\n",
       "  [['cephalosporin', 'erythromycin'], 0],\n",
       "  [['cephalosporin', 'rifampin'], 0],\n",
       "  [['cephalosporin', 'tetracycline'], 0],\n",
       "  [['chamber', 'federation'], 0],\n",
       "  [['characteristic', 'element'], 1],\n",
       "  [['cheese', 'cream'], 0],\n",
       "  [['cheese', 'urine'], 0],\n",
       "  [['child', 'analgesic'], 0],\n",
       "  [['child', 'nanny'], 0],\n",
       "  [['child', 'nausea'], 0],\n",
       "  [['child', 'pericarditis'], 0],\n",
       "  [['child', 'pregnancy'], 0],\n",
       "  [['child', 'sherry'], 0],\n",
       "  [['child', 'vaccine'], 0],\n",
       "  [['chisel', 'EAST'], 0],\n",
       "  [['chisel', 'handshake'], 0],\n",
       "  [['chisel', 'item'], 0],\n",
       "  [['chisel', 'lighthouse'], 0],\n",
       "  [['chisel', 'nutcracker'], 0],\n",
       "  [['chisel', 'pincer'], 0],\n",
       "  [['chisel', 'plier'], 0],\n",
       "  [['chisel', 'rake'], 0],\n",
       "  [['chisel', 'rectification'], 0],\n",
       "  [['chisel', 'serving'], 0],\n",
       "  [['chisel', 'shovel'], 0],\n",
       "  [['chisel', 'smaws'], 0],\n",
       "  [['chisel', 'spoon'], 0],\n",
       "  [['chisel', 'steel'], 0],\n",
       "  [['chisel', 'temperature'], 0],\n",
       "  [['chisel', 'trekking'], 0],\n",
       "  [['chisel', 'website'], 0],\n",
       "  [['chloride', 'nausea'], 0],\n",
       "  [['chorioretinitis', 'atrophy'], 0],\n",
       "  [['chorioretinitis', 'insanity'], 0],\n",
       "  [['chorioretinitis', 'neuritis'], 0],\n",
       "  [['chorioretinitis', 'papillitis'], 0],\n",
       "  [['chorioretinitis', 'paresis'], 0],\n",
       "  [['chun', 'sentence'], 0],\n",
       "  [['city', 'urban'], 1],\n",
       "  [['clarinet', 'boxer'], 0],\n",
       "  [['clarinet', 'device'], 1],\n",
       "  [['clarinet', 'fat'], 0],\n",
       "  [['clarinet', 'glove'], 0],\n",
       "  [['clarinet', 'hole'], 0],\n",
       "  [['clarinet', 'horn'], 0],\n",
       "  [['clarinet', 'instrument'], 1],\n",
       "  [['clarinet', 'kazoo'], 0],\n",
       "  [['clarinet', 'key'], 0],\n",
       "  [['clarinet', 'sax'], 0],\n",
       "  [['clarinet', 'storage'], 0],\n",
       "  [['clarinet', 'violin'], 0],\n",
       "  [['clarinet', 'wood'], 0],\n",
       "  [['cloak', 'angling'], 0],\n",
       "  [['cloak', 'by-election'], 0],\n",
       "  [['cloak', 'cohort'], 0],\n",
       "  [['cloak', 'contravention'], 0],\n",
       "  [['cloak', 'fold'], 0],\n",
       "  [['cloak', 'garment'], 1],\n",
       "  [['cloak', 'glitch'], 0],\n",
       "  [['cloak', 'glove'], 0],\n",
       "  [['cloak', 'hat'], 0],\n",
       "  [['cloak', 'humanity'], 0],\n",
       "  [['cloak', 'jacket'], 0],\n",
       "  [['cloak', 'material'], 0],\n",
       "  [['cloak', 'pattern'], 0],\n",
       "  [['cloak', 'pullover'], 0],\n",
       "  [['cloak', 'scarf'], 0],\n",
       "  [['cloak', 'syphilis'], 0],\n",
       "  [['cloak', 'underpants'], 0],\n",
       "  [['cloak', 'vest'], 0],\n",
       "  [['cloak', 'wear'], 1],\n",
       "  [['cloak', 'youngster'], 0],\n",
       "  [['cns', 'heart'], 0],\n",
       "  [['coal', 'goods'], 1],\n",
       "  [['cod', 'bed'], 0],\n",
       "  [['cod', 'bowler'], 0],\n",
       "  [['cod', 'cancellation'], 0],\n",
       "  [['cod', 'carp'], 0],\n",
       "  [['cod', 'chordate'], 1],\n",
       "  [['cod', 'eye'], 0],\n",
       "  [['cod', 'fin'], 0],\n",
       "  [['cod', 'fish'], 1],\n",
       "  [['cod', 'gender'], 0],\n",
       "  [['cod', 'goldfish'], 0],\n",
       "  [['cod', 'incident'], 0],\n",
       "  [['cod', 'salmon'], 0],\n",
       "  [['cod', 'seafood'], 1],\n",
       "  [['cod', 'splice'], 0],\n",
       "  [['cod', 'trio'], 0],\n",
       "  [['cod', 'trout'], 0],\n",
       "  [['cod', 'urine'], 0],\n",
       "  [['cod', 'whale'], 0],\n",
       "  [['codeine', 'acetaminophen'], 0],\n",
       "  [['codeine', 'analgesic'], 1],\n",
       "  [['codeine', 'camphor'], 0],\n",
       "  [['codeine', 'methadone'], 0],\n",
       "  [['codeine', 'phenylbutazone'], 0],\n",
       "  [['codeine', 'trichloroethylene'], 0],\n",
       "  [['cola', 'stimulant'], 0],\n",
       "  [['collection', 'parasite'], 0],\n",
       "  [['compass', 'direction'], 1],\n",
       "  [['compass', 'instrument'], 1],\n",
       "  [['confederation', 'federation'], 1],\n",
       "  [['confusion', 'cramp'], 0],\n",
       "  [['confusion', 'depression'], 0],\n",
       "  [['confusion', 'fatigue'], 0],\n",
       "  [['confusion', 'weakness'], 0],\n",
       "  [['consortium', 'federation'], 0],\n",
       "  [['consortium', 'government'], 0],\n",
       "  [['contraceptive', 'pill'], 1],\n",
       "  [['conviction', 'sentence'], 0],\n",
       "  [['cornerstone', 'element'], 1],\n",
       "  [['costume', 'gender'], 1],\n",
       "  [['cough', 'aspiration'], 0],\n",
       "  [['cough', 'atelectasis'], 0],\n",
       "  [['cough', 'illness'], 1],\n",
       "  [['cough', 'meningitis'], 0],\n",
       "  [['cough', 'mumps'], 0],\n",
       "  [['cough', 'sickness'], 1],\n",
       "  [['count', 'sentence'], 0],\n",
       "  [['country', 'government'], 0],\n",
       "  [['course', 'element'], 1],\n",
       "  [['cows', 'animals'], 1],\n",
       "  [['crack', 'glass'], 1],\n",
       "  [['cramp', 'confusion'], 0],\n",
       "  [['cramp', 'depression'], 0],\n",
       "  [['cramp', 'fatigue'], 0],\n",
       "  [['cramp', 'polycythemia'], 0],\n",
       "  [['cramp', 'weakness'], 0],\n",
       "  [['cream', 'cheese'], 0],\n",
       "  [['cream', 'urine'], 0],\n",
       "  [['credit', 'liquidity'], 0],\n",
       "  [['crew', 'warplane'], 1],\n",
       "  [['criticism', 'element'], 0],\n",
       "  [['criticize', 'castigate'], 0],\n",
       "  [['crude', 'goods'], 0],\n",
       "  [['csf', 'lymphocyte'], 0],\n",
       "  [['cute', 'adorable'], 1],\n",
       "  [['cyclase', 'heart'], 0],\n",
       "  [['cyclase', 'phosphorylase'], 0],\n",
       "  [['cylinder', 'bottle'], 0],\n",
       "  [['cytotoxicity', 'cancer'], 0],\n",
       "  [['cytotoxicity', 'radical'], 0],\n",
       "  [['dancer', 'autobiography'], 0],\n",
       "  [['dead', 'rot'], 0],\n",
       "  [['decrease', 'change'], 1],\n",
       "  [['defection', 'federation'], 0],\n",
       "  [['defiantly', 'cooperate'], 0],\n",
       "  [['dehydroepiandrosterone', 'androgen'], 0],\n",
       "  [['dehydroepiandrosterone', 'pregnenolone'], 0],\n",
       "  [['depression', 'abstinence'], 0],\n",
       "  [['depression', 'anemia'], 0],\n",
       "  [['depression', 'anxiety'], 0],\n",
       "  [['depression', 'bleeding'], 0],\n",
       "  [['depression', 'confusion'], 0],\n",
       "  [['depression', 'cramp'], 0],\n",
       "  [['depression', 'disease'], 1],\n",
       "  [['depression', 'dizziness'], 0],\n",
       "  [['depression', 'fatigue'], 0],\n",
       "  [['depression', 'hyperthyroidism'], 0],\n",
       "  [['depression', 'irritability'], 0],\n",
       "  [['depression', 'meningitis'], 0],\n",
       "  [['depression', 'nausea'], 0],\n",
       "  [['depression', 'rash'], 0],\n",
       "  [['depression', 'stress'], 0],\n",
       "  [['depression', 'tenosynovitis'], 0],\n",
       "  [['depression', 'weakness'], 0],\n",
       "  [['detective', 'policeman'], 1],\n",
       "  [['diet', 'analgesic'], 0],\n",
       "  [['diet', 'androgen'], 0],\n",
       "  [['diet', 'bacteria'], 0],\n",
       "  [['diet', 'bleeding'], 0],\n",
       "  [['diet', 'fruit'], 0],\n",
       "  [['diet', 'massage'], 0],\n",
       "  [['diet', 'parasite'], 0],\n",
       "  [['diet', 'peristalsis'], 0],\n",
       "  [['diet', 'pregnancy'], 0],\n",
       "  [['diet', 'stress'], 0],\n",
       "  [['diet', 'tapeworm'], 0],\n",
       "  [['diet', 'testosterone'], 0],\n",
       "  [['diet', 'verapamil'], 0],\n",
       "  [['digit', 'iv'], 0],\n",
       "  [['digit', 'ix'], 0],\n",
       "  [['ding', 'bumper'], 1],\n",
       "  [['disdain', 'hatred'], 0],\n",
       "  [['disease', 'bacteria'], 0],\n",
       "  [['disease', 'cellulitis'], 0],\n",
       "  [['disease', 'depression'], 0],\n",
       "  [['disease', 'fungi'], 0],\n",
       "  [['disease', 'gall'], 0],\n",
       "  [['disease', 'herpes'], 0],\n",
       "  [['disease', 'illness'], 1],\n",
       "  [['disease', 'meningitis'], 0],\n",
       "  [['disease', 'nausea'], 0],\n",
       "  [['disease', 'oxidation'], 0],\n",
       "  [['disease', 'peritonitis'], 0],\n",
       "  [['disease', 'radical'], 0],\n",
       "  [['disease', 'rubella'], 0],\n",
       "  [['disease', 'sickness'], 1],\n",
       "  [['disease', 'syphilis'], 0],\n",
       "  [['disgusting', 'tasty'], 0],\n",
       "  [['distortion', 'liquidity'], 0],\n",
       "  [['divide', 'parts'], 1],\n",
       "  [['dizziness', 'anxiety'], 0],\n",
       "  [['dizziness', 'depression'], 0],\n",
       "  [['dizziness', 'hunger'], 0],\n",
       "  [['dizziness', 'irritability'], 0],\n",
       "  [['dizziness', 'meningitis'], 0],\n",
       "  [['dizziness', 'nausea'], 0],\n",
       "  [['dizziness', 'rash'], 0],\n",
       "  [['dizziness', 'stress'], 0],\n",
       "  [['documentation', 'information'], 1],\n",
       "  [['earth', 'planet'], 1],\n",
       "  [['editor', 'worker'], 1],\n",
       "  [['eggs', 'omelette'], 0],\n",
       "  [['electrician', 'worker'], 1],\n",
       "  [['electricity', 'goods'], 0],\n",
       "  [['element', 'agenda'], 0],\n",
       "  [['element', 'aspect'], 1],\n",
       "  [['element', 'breakdown'], 0],\n",
       "  [['element', 'characteristic'], 1],\n",
       "  [['element', 'cornerstone'], 1],\n",
       "  [['element', 'course'], 0],\n",
       "  [['element', 'criticism'], 0],\n",
       "  [['element', 'legality'], 0],\n",
       "  [['element', 'loosening'], 0],\n",
       "  [['element', 'package'], 0],\n",
       "  [['element', 'part'], 1],\n",
       "  [['element', 'participation'], 0],\n",
       "  [['element', 'purpose'], 0],\n",
       "  [['element', 'understanding'], 0],\n",
       "  [['eligibility', 'sentence'], 0],\n",
       "  [['emotion', 'fright'], 0],\n",
       "  [['encephalopathy', 'arteritis'], 0],\n",
       "  [['encephalopathy', 'meningitis'], 0],\n",
       "  [['encephalopathy', 'syphilis'], 0],\n",
       "  [['encephalopathy', 'tumour'], 0],\n",
       "  [['enolase', 'anhydrase'], 0],\n",
       "  [['epilepsy', 'nausea'], 0],\n",
       "  [['equipment', 'goods'], 1],\n",
       "  [['equipment', 'parachute'], 0],\n",
       "  [['equipment', 'reel'], 0],\n",
       "  [['equipment', 'sherry'], 0],\n",
       "  [['erysipelas', 'sycosis'], 0],\n",
       "  [['erythromycin', 'aminoglycosides'], 0],\n",
       "  [['erythromycin', 'carbenicillin'], 0],\n",
       "  [['erythromycin', 'cephalosporin'], 0],\n",
       "  [['erythromycin', 'rifampin'], 0],\n",
       "  [['erythromycin', 'tetracycline'], 0],\n",
       "  [['erythropoiesis', 'angiogenesis'], 0],\n",
       "  [['excuse', 'physician'], 0],\n",
       "  [['exercising', 'stretching'], 1],\n",
       "  [['expenditure', 'liquidity'], 1],\n",
       "  [['extension', 'sentence'], 0],\n",
       "  [['fabric', 'velvet'], 0],\n",
       "  [['factory', 'goods'], 1],\n",
       "  [['factory', 'tires'], 1],\n",
       "  [['falcon', 'Aussie'], 0],\n",
       "  [['falcon', 'arrogance'], 0],\n",
       "  [['falcon', 'bird'], 1],\n",
       "  [['falcon', 'calculation'], 0],\n",
       "  [['falcon', 'chordate'], 1],\n",
       "  [['falcon', 'editor'], 0],\n",
       "  [['falcon', 'eye'], 0],\n",
       "  [['falcon', 'foot'], 0],\n",
       "  [['falcon', 'goose'], 0],\n",
       "  [['falcon', 'immigration'], 0],\n",
       "  [['falcon', 'operator'], 0],\n",
       "  [['falcon', 'plumage'], 0],\n",
       "  [['falcon', 'plume'], 0],\n",
       "  [['falcon', 'raptor'], 1],\n",
       "  [['falcon', 'robin'], 0],\n",
       "  [['falcon', 'sentencing'], 0],\n",
       "  [['falcon', 'sparrow'], 0],\n",
       "  [['falcon', 'stab'], 0],\n",
       "  [['falcon', 'thou'], 0],\n",
       "  [['falcon', 'underdog'], 0],\n",
       "  [['falcon', 'vulture'], 0],\n",
       "  [['falcon', 'worksheet'], 0],\n",
       "  [['fat', 'thin'], 0],\n",
       "  [['fatigue', 'anxiety'], 0],\n",
       "  [['fatigue', 'bleeding'], 0],\n",
       "  [['fatigue', 'confusion'], 0],\n",
       "  [['fatigue', 'cramp'], 0],\n",
       "  [['fatigue', 'depression'], 0],\n",
       "  [['fatigue', 'irritability'], 0],\n",
       "  [['fatigue', 'jitteriness'], 0],\n",
       "  [['fatigue', 'pallor'], 0],\n",
       "  [['fatigue', 'pancytopenia'], 0],\n",
       "  [['fatigue', 'pregnancy'], 0],\n",
       "  [['fatigue', 'tapeworm'], 0],\n",
       "  [['fatigue', 'vasoconstriction'], 0],\n",
       "  [['fatigue', 'weakness'], 1],\n",
       "  [['federation', 'activist'], 0],\n",
       "  [['federation', 'advisories'], 0],\n",
       "  [['federation', 'chamber'], 1],\n",
       "  [['federation', 'confederation'], 1],\n",
       "  [['federation', 'consortium'], 0],\n",
       "  [['federation', 'defection'], 0],\n",
       "  [['federation', 'ministry'], 0],\n",
       "  [['federation', 'premier'], 1],\n",
       "  [['federation', 'presidency'], 1],\n",
       "  [['federation', 'promoter'], 0],\n",
       "  [['fertilization', 'ovum'], 0],\n",
       "  [['finance', 'management'], 1],\n",
       "  [['fish', 'fin'], 1],\n",
       "  [['fish', 'trout'], 0],\n",
       "  [['fixed', 'irreparable'], 0],\n",
       "  [['flashlight', 'battery'], 0],\n",
       "  [['flashlight', 'bulb'], 1],\n",
       "  [['foot', 'inch'], 1],\n",
       "  [['foot', 'toe'], 1],\n",
       "  [['forgiving', 'vengeful'], 0],\n",
       "  [['fright', 'emotion'], 1],\n",
       "  [['frog', 'bandanna'], 0],\n",
       "  [['frog', 'calendar'], 0],\n",
       "  [['frog', 'chordate'], 1],\n",
       "  [['frog', 'dividend'], 0],\n",
       "  [['frog', 'doyen'], 0],\n",
       "  [['frog', 'ethnology'], 0],\n",
       "  [['frog', 'eye'], 0],\n",
       "  [['frog', 'foot'], 0],\n",
       "  [['frog', 'headwaters'], 0],\n",
       "  [['frog', 'pgce'], 0],\n",
       "  [['frog', 'poison'], 0],\n",
       "  [['fruit', 'berry'], 0],\n",
       "  [['fruit', 'diet'], 1],\n",
       "  [['fruit', 'grape'], 0],\n",
       "  [['fruit', 'illness'], 0],\n",
       "  [['fruit', 'lemon'], 0],\n",
       "  [['fruit', 'vegetable'], 0],\n",
       "  [['fungi', 'bacillus'], 0],\n",
       "  [['fungi', 'bacteria'], 0],\n",
       "  [['fungi', 'disease'], 0],\n",
       "  [['fungi', 'illness'], 0],\n",
       "  [['gall', 'disease'], 1],\n",
       "  [['gallon', 'ounce'], 1],\n",
       "  [['game', 'bowling'], 0],\n",
       "  [['game', 'netball'], 0],\n",
       "  [['garage', 'cars'], 1],\n",
       "  [['gathering', 'seminar'], 0],\n",
       "  [['gender', 'costume'], 0],\n",
       "  [['generator', 'apparatus'], 1],\n",
       "  [['give', 'receiver'], 1],\n",
       "  [['glass', 'goods'], 1],\n",
       "  [['glass', 'meal'], 0],\n",
       "  [['glass', 'pane'], 1],\n",
       "  [['glove', 'brainchild'], 0],\n",
       "  [['glove', 'cap'], 0],\n",
       "  [['glove', 'cashmere'], 0],\n",
       "  [['glove', 'cloak'], 0],\n",
       "  [['glove', 'country'], 0],\n",
       "  [['glove', 'fabric'], 0],\n",
       "  [['glove', 'garment'], 1],\n",
       "  [['glove', 'glass'], 0],\n",
       "  [['glove', 'goose'], 0],\n",
       "  [['glove', 'graffito'], 0],\n",
       "  [['glove', 'hat'], 0],\n",
       "  [['glove', 'inc'], 0],\n",
       "  [['glove', 'informer'], 0],\n",
       "  [['glove', 'inspection'], 0],\n",
       "  [['glove', 'intellect'], 0],\n",
       "  [['glove', 'jacket'], 0],\n",
       "  [['glove', 'material'], 0],\n",
       "  [['glove', 'openchoice'], 0],\n",
       "  [['glove', 'pest'], 0],\n",
       "  [['glove', 'pullover'], 0],\n",
       "  [['glove', 'pyrolysis'], 0],\n",
       "  [['glove', 'scarf'], 0],\n",
       "  [['glove', 'species'], 0],\n",
       "  [['glove', 'ten'], 0],\n",
       "  [['glove', 'underpants'], 0],\n",
       "  [['glove', 'understanding'], 0],\n",
       "  [['glove', 'vest'], 0],\n",
       "  [['glove', 'wear'], 1],\n",
       "  [['gold', 'goods'], 1],\n",
       "  [['golden', 'gleam'], 0],\n",
       "  [['goldfish', 'carp'], 0],\n",
       "  [['goldfish', 'chordate'], 1],\n",
       "  [['goldfish', 'cod'], 0],\n",
       "  [['goldfish', 'contraceptive'], 0],\n",
       "  [['goldfish', 'coven'], 0],\n",
       "  [['goldfish', 'eye'], 0],\n",
       "  [['goldfish', 'fin'], 0],\n",
       "  [['goldfish', 'fish'], 1],\n",
       "  [['goldfish', 'label'], 0],\n",
       "  [['goldfish', 'monarchy'], 0],\n",
       "  [['goldfish', 'pet'], 1],\n",
       "  [['goldfish', 'salmon'], 0],\n",
       "  [['goldfish', 'trout'], 0],\n",
       "  [['goldfish', 'whale'], 0],\n",
       "  [['goods', 'cashmere'], 0],\n",
       "  [['goods', 'coal'], 1],\n",
       "  [['goods', 'crude'], 0],\n",
       "  [['goods', 'electricity'], 0],\n",
       "  [['goods', 'equipment'], 0],\n",
       "  [['goods', 'glass'], 0],\n",
       "  [['goods', 'gold'], 0],\n",
       "  [['goods', 'import'], 0],\n",
       "  [['goods', 'item'], 1],\n",
       "  [['goods', 'material'], 1],\n",
       "  [['goods', 'steel'], 0],\n",
       "  [['goose', 'attitude'], 0],\n",
       "  [['goose', 'bird'], 1],\n",
       "  [['goose', 'chordate'], 1],\n",
       "  [['goose', 'curriculum'], 0],\n",
       "  [['goose', 'doubter'], 0],\n",
       "  [['goose', 'dwarve'], 0],\n",
       "  [['goose', 'eye'], 0],\n",
       "  [['goose', 'falcon'], 0],\n",
       "  [['goose', 'foot'], 0],\n",
       "  [['goose', 'gosling'], 0],\n",
       "  [['goose', 'indexing'], 0],\n",
       "  [['goose', 'juxtaposition'], 0],\n",
       "  [['goose', 'monograph'], 0],\n",
       "  [['goose', 'panic'], 0],\n",
       "  [['goose', 'plumage'], 0],\n",
       "  [['goose', 'plume'], 0],\n",
       "  [['goose', 'reading'], 0],\n",
       "  [['goose', 'robin'], 0],\n",
       "  [['goose', 'signatory'], 0],\n",
       "  [['goose', 'sparrow'], 0],\n",
       "  [['goose', 'stud'], 0],\n",
       "  [['goose', 'vulture'], 0],\n",
       "  [['government', 'administration'], 1],\n",
       "  [['government', 'authority'], 1],\n",
       "  [['government', 'consortium'], 0],\n",
       "  [['government', 'country'], 0],\n",
       "  [['government', 'ministry'], 0],\n",
       "  [['government', 'parliament'], 0],\n",
       "  [['government', 'partner'], 0],\n",
       "  [['government', 'politician'], 0],\n",
       "  [['government', 'premier'], 1],\n",
       "  [['government', 'presidency'], 0],\n",
       "  [['grandchild', 'relative'], 1],\n",
       "  [['grape', 'berry'], 1],\n",
       "  [['grape', 'currant'], 0],\n",
       "  [['grape', 'disagreement'], 0],\n",
       "  [['grape', 'essay'], 0],\n",
       "  [['grape', 'fruit'], 1],\n",
       "  [['grape', 'hoax'], 0],\n",
       "  [['grape', 'lemon'], 0],\n",
       "  [['grape', 'lineup'], 0],\n",
       "  [['grape', 'montanes'], 0],\n",
       "  [['grape', 'pathway'], 0],\n",
       "  [['graphics', 'stencil'], 1],\n",
       "  [['grasshopper', 'CR'], 0],\n",
       "  [['grasshopper', 'bee'], 0],\n",
       "  [['grasshopper', 'bus'], 0],\n",
       "  [['grasshopper', 'convenience'], 0],\n",
       "  [['grasshopper', 'cricket'], 0],\n",
       "  [['grasshopper', 'crimestoppers'], 0],\n",
       "  [['grasshopper', 'gold'], 0],\n",
       "  [['grasshopper', 'invertebrate'], 1],\n",
       "  [['grasshopper', 'line'], 0],\n",
       "  [['grasshopper', 'local'], 0],\n",
       "  [['grasshopper', 'malediction'], 0],\n",
       "  [['grasshopper', 'touch'], 0],\n",
       "  [['grenade', 'Kalashnikov'], 0],\n",
       "  [['grenade', 'bomb'], 0],\n",
       "  [['grenade', 'bow'], 0],\n",
       "  [['grenade', 'device'], 1],\n",
       "  [['grenade', 'front-end'], 0],\n",
       "  [['grenade', 'inscription'], 0],\n",
       "  [['grenade', 'kalashnikov'], 0],\n",
       "  [['grenade', 'malediction'], 0],\n",
       "  [['grenade', 'mucosa'], 0],\n",
       "  [['grenade', 'petrol'], 0],\n",
       "  [['grenade', 'pike'], 0],\n",
       "  [['grenade', 'prejudice'], 0],\n",
       "  [['grenade', 'recruitment'], 0],\n",
       "  [['grenade', 'revolver'], 0],\n",
       "  [['grenade', 'sentencing'], 0],\n",
       "  [['grenade', 'steel'], 0],\n",
       "  [['grenade', 'theconurbation'], 0],\n",
       "  [['gum', 'weakness'], 0],\n",
       "  [['haematemesis', 'anemia'], 0],\n",
       "  [['haematemesis', 'bleeding'], 0],\n",
       "  [['haematemesis', 'bronchospasm'], 0],\n",
       "  [['haematemesis', 'nausea'], 0],\n",
       "  [['handgun', 'instrument'], 1],\n",
       "  [['handgun', 'worker'], 0],\n",
       "  [['handset', 'equipment'], 1],\n",
       "  [['hare', 'mammal'], 1],\n",
       "  [['harvest', 'reaping'], 0],\n",
       "  [['hat', 'alnguages'], 0],\n",
       "  [['hat', 'ammunition'], 0],\n",
       "  [['hat', 'cap'], 0],\n",
       "  [['hat', 'cloak'], 0],\n",
       "  [['hat', 'comparison'], 0],\n",
       "  [['hat', 'fair'], 0],\n",
       "  [['hat', 'fascist'], 0],\n",
       "  [['hat', 'felt'], 0],\n",
       "  [['hat', 'follow-up'], 0],\n",
       "  [['hat', 'garment'], 1],\n",
       "  [['hat', 'glove'], 0],\n",
       "  [['hat', 'guild'], 0],\n",
       "  [['hat', 'impunity'], 0],\n",
       "  [['hat', 'ingrate'], 0],\n",
       "  [['hat', 'instrumentation'], 0],\n",
       "  [['hat', 'jacket'], 0],\n",
       "  [['hat', 'jury'], 0],\n",
       "  [['hat', 'meal'], 0],\n",
       "  [['hat', 'olisten'], 0],\n",
       "  [['hat', 'photographer'], 0],\n",
       "  [['hat', 'pullover'], 0],\n",
       "  [['hat', 'scarf'], 0],\n",
       "  [['hat', 'sultan'], 0],\n",
       "  [['hat', 'summit'], 0],\n",
       "  [['hat', 'sushi'], 0],\n",
       "  [['hat', 'trip'], 0],\n",
       "  [['hat', 'underpants'], 0],\n",
       "  [['hat', 'vest'], 0],\n",
       "  [['hat', 'wear'], 1],\n",
       "  [['heal', 'injure'], 0],\n",
       "  [['heart', 'cns'], 0],\n",
       "  [['heart', 'cyclase'], 0],\n",
       "  [['heart', 'vasoconstriction'], 0],\n",
       "  [['hedge', 'fence'], 0],\n",
       "  [['hen', 'bird'], 1],\n",
       "  [['herpes', 'disease'], 1],\n",
       "  [['highway', 'road'], 1],\n",
       "  [['honest', 'liar'], 0],\n",
       "  [['hop', 'rabbit'], 0],\n",
       "  [['horse', 'benediction'], 0],\n",
       "  [['horse', 'chordate'], 1],\n",
       "  [['horse', 'circle'], 0],\n",
       "  [['horse', 'dice'], 0],\n",
       "  [['horse', 'eye'], 0],\n",
       "  [['horse', 'foot'], 0],\n",
       "  [['horse', 'gathering'], 0],\n",
       "  [['horse', 'hoof'], 0],\n",
       "  [['horse', 'horseback'], 0],\n",
       "  [['horse', 'mammal'], 1],\n",
       "  [['horse', 'mule'], 0],\n",
       "  [['horse', 'muzzle'], 0],\n",
       "  [['horse', 'nose'], 0],\n",
       "  [['horse', 'outfit'], 0],\n",
       "  [['horse', 'pike'], 0],\n",
       "  [['horse', 'rabbit'], 0],\n",
       "  [['horse', 'seaplane'], 0],\n",
       "  [['horse', 'sheep'], 0],\n",
       "  [['horse', 'star'], 0],\n",
       "  [['horse', 'tiger'], 0],\n",
       "  [['horse', 'wanderer'], 0],\n",
       "  [['horse', 'whale'], 0],\n",
       "  [['host', 'hostess'], 0],\n",
       "  [['hostess', 'host'], 1],\n",
       "  [['humanity', 'sentence'], 0],\n",
       "  [['hunger', 'arteritis'], 0],\n",
       "  [['hunger', 'dizziness'], 0],\n",
       "  [['hunger', 'hypoglycemia'], 0],\n",
       "  [['hunger', 'irritability'], 0],\n",
       "  [['hunger', 'meningitis'], 0],\n",
       "  [['hunger', 'nausea'], 0],\n",
       "  [['hunger', 'starving'], 0],\n",
       "  [['hunger', 'stress'], 0],\n",
       "  [['hunger', 'syphilis'], 0],\n",
       "  [['hunger', 'tumour'], 0],\n",
       "  [['hurting', 'comfort'], 0],\n",
       "  [['hyperthyroidism', 'anxiety'], 0],\n",
       "  [['hyperthyroidism', 'depression'], 0],\n",
       "  [['hypnotic', 'trazodone'], 0],\n",
       "  [['hypoglycemia', 'arteritis'], 0],\n",
       "  [['hypoglycemia', 'hunger'], 0],\n",
       "  [['hypoglycemia', 'meningitis'], 0],\n",
       "  [['hypoglycemia', 'stress'], 0],\n",
       "  [['hypoglycemia', 'syphilis'], 0],\n",
       "  [['hypoglycemia', 'tumour'], 0],\n",
       "  [['illness', 'asylum'], 0],\n",
       "  [['illness', 'bacteria'], 0],\n",
       "  [['illness', 'cellulitis'], 0],\n",
       "  [['illness', 'digit'], 0],\n",
       "  [['illness', 'disease'], 1],\n",
       "  [['illness', 'fungi'], 0],\n",
       "  [['illness', 'meningitis'], 0],\n",
       "  [['illness', 'peritonitis'], 0],\n",
       "  [['illness', 'rubella'], 0],\n",
       "  [['illness', 'syphilis'], 0],\n",
       "  [['illness', 'tumour'], 0],\n",
       "  [['import', 'goods'], 0],\n",
       "  [['information', 'corporation'], 0],\n",
       "  [['information', 'disease'], 0],\n",
       "  [['information', 'documentation'], 0],\n",
       "  [['information', 'surgeon'], 0],\n",
       "  [['infrastructure', 'management'], 0],\n",
       "  [['injure', 'heal'], 0],\n",
       "  [['insanity', 'atrophy'], 0],\n",
       "  [['insanity', 'chorioretinitis'], 0],\n",
       "  [['insanity', 'neuritis'], 1],\n",
       "  [['insanity', 'papillitis'], 0],\n",
       "  [['insanity', 'paresis'], 0],\n",
       "  [['insist', 'assert'], 1],\n",
       "  [['instrument', 'violin'], 0],\n",
       "  [['internment', 'captivity'], 1],\n",
       "  [['intranet', 'system'], 1],\n",
       "  [['investment', 'transaction'], 1],\n",
       "  [['irreparable', 'fixed'], 0],\n",
       "  [['irritability', 'amphetamine'], 0],\n",
       "  [['irritability', 'anxiety'], 1],\n",
       "  [['irritability', 'depression'], 0],\n",
       "  [['irritability', 'dizziness'], 0],\n",
       "  [['irritability', 'fatigue'], 0],\n",
       "  [['irritability', 'hunger'], 0],\n",
       "  [['irritability', 'jitteriness'], 1],\n",
       "  [['irritability', 'meningitis'], 0],\n",
       "  [['irritability', 'nausea'], 0],\n",
       "  [['irritability', 'stress'], 1],\n",
       "  [['irritability', 'vasoconstriction'], 0],\n",
       "  [['itching', 'anxiety'], 0],\n",
       "  [['itching', 'nausea'], 0],\n",
       "  [['itching', 'rash'], 0],\n",
       "  [['itching', 'rhinorrhea'], 0],\n",
       "  [['item', 'goods'], 0],\n",
       "  [['iv', 'digit'], 1],\n",
       "  [['ix', 'digit'], 1],\n",
       "  [['jacket', 'Anti-Terrorism'], 0],\n",
       "  [['jacket', 'button'], 0],\n",
       "  [['jacket', 'cloak'], 0],\n",
       "  ...],\n",
       " 'macro-F1': 0.6584529946515524,\n",
       " 'vector_func': <function __main__.glove_vec(w)>,\n",
       " 'vector_combo_func': <function __main__.vec_concatenate(u, v)>}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nli.wordentail_experiment(train_data=wordentail_data['train'],\n",
    "#                                   assess_data=wordentail_data['dev'],\n",
    "#                                   model=model,\n",
    "#                                   vector_func=glove_vec,\n",
    "#                                   vector_combo_func=vec_concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 121. Training loss did not improve more than tol=1e-05. Final error is 0.0703607730101794."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.885     0.889     0.887      1732\n",
      "           1      0.409     0.398     0.404       334\n",
      "\n",
      "    accuracy                          0.810      2066\n",
      "   macro avg      0.647     0.644     0.645      2066\n",
      "weighted avg      0.808     0.810     0.809      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "#   3) The score achieved by your system in place of MY_NUMBER.\n",
    "#        With no other changes to that line.\n",
    "#        You should report your score as a decimal value <=1.0\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# IMPORT ANY MODULES BELOW THE 'IS_GRADESCOPE_ENV' CHECK CONDITION. DOING\n",
    "# SO ABOVE THE CHECK MAY CAUSE THE AUTOGRADER TO FAIL.\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "# The original system is built using a one-hidden layer neural classifier with dropout.\n",
    "# The input consist of the concatenation of the embedding (GLoVe 300d) of the two words.\n",
    "# As a baseline I used as embedding GloVe 50d and estimated the performance.\n",
    "# The final model is trained using GLoVe 300d, additionally, I used the SMOTE technique to handle class imbalance.\n",
    "\n",
    "\n",
    "class MYClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self, dropout_prob=0.7, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.params += ['dropout_prob']\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"Complete this method!\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        an `nn.Module` instance, which can be a free-standing class you\n",
    "        write yourself, as in `torch_rnn_classifier`, or the outpiut of\n",
    "        `nn.Sequential`, as in `torch_shallow_neural_classifier`.\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "        ##### YOUR CODE HERE\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.Dropout(self.dropout_prob),\n",
    "            self.hidden_activation,\n",
    "            nn.Linear(self.hidden_dim, self.n_classes_))\n",
    "    \n",
    "    def build_dataset(self, X, y=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        self.input_dim = X.shape[1]\n",
    "        \n",
    "        if y is None:\n",
    "            X = torch.FloatTensor(X)\n",
    "            dataset = torch.utils.data.TensorDataset(X)\n",
    "        else:\n",
    "            self.classes_ = sorted(set(y))\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            y = [class2index[label] for label in y]\n",
    "            X, y = oversample.fit_resample(X, y)\n",
    "            X = torch.FloatTensor(X)\n",
    "            y = torch.tensor(y)\n",
    "            dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        return dataset\n",
    "\n",
    "# def load_glove300():\n",
    "#     glove_src = os.path.join(GLOVE_HOME, 'glove.6B.300d.txt')\n",
    "#     # Creates a dict mapping strings (words) to GloVe vectors\n",
    "#     GLOVE = utils.glove2dict(glove_src)\n",
    "#     return GLOVE\n",
    "\n",
    "# GLOVE = load_glove300()\n",
    "\n",
    "# def glove_vec(w):\n",
    "#     \"\"\"Return `w`'s GloVe representation if available, else return\n",
    "#     a random vector.\"\"\"\n",
    "#     return GLOVE.get(w, randvec(w, n=300))\n",
    "\n",
    "# My peak score was: 0.658 \n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    oversample = SMOTE()\n",
    "    def load_glove300():\n",
    "        glove_src = os.path.join(GLOVE_HOME, 'glove.6B.300d.txt')\n",
    "    # Creates a dict mapping strings (words) to GloVe vectors\n",
    "        GLOVE = utils.glove2dict(glove_src)\n",
    "        return GLOVE\n",
    "\n",
    "    GLOVE = load_glove300()\n",
    "\n",
    "    def glove_vec(w):\n",
    "        \"\"\"Return `w`'s GloVe representation if available, else return\n",
    "        a random vector.\"\"\"\n",
    "        return GLOVE.get(w, randvec(w, n=300))\n",
    "\n",
    "    model = MYClassifier(dropout_prob=0.4, eta=0.001, hidden_dim=300)\n",
    "    nli.wordentail_experiment(train_data=wordentail_data['train'],\n",
    "                                  assess_data=wordentail_data['dev'],\n",
    "                                  model=model,\n",
    "                                  vector_func=glove_vec,\n",
    "                                  vector_combo_func=vec_concatenate)\n",
    "    \n",
    "\n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bake-off [1 point]\n",
    "\n",
    "The goal of the bake-off is to achieve the highest __macro-average F1__ score on a test set that we will make available at the start of the bake-off. The announcement will go out on the discussion forum. To enter, you'll be asked to run `nli.bake_off_evaluation` on the output of your chosen `nli.wordentail_experiment` run. \n",
    "\n",
    "The cells below this one constitute your bake-off entry.\n",
    "\n",
    "The rules described in the [Your original system](#Your-original-system-[3-points]) homework question are also in effect for the bake-off.\n",
    "\n",
    "Systems that enter will receive the additional homework point, and systems that achieve the top score will receive an additional 0.5 points. We will test the top-performing systems ourselves, and only systems for which we can reproduce the reported results will win the extra 0.5 points.\n",
    "\n",
    "Late entries will be accepted, but they cannot earn the extra 0.5 points. Similarly, you cannot win the bake-off unless your homework is submitted on time.\n",
    "\n",
    "The announcement will include the details on where to submit your entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your bake-off assessment code into this cell.\n",
    "# Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    pass\n",
    "    # Please enter your code in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On an otherwise blank line in this cell, please enter\n",
    "# your macro-avg f1 value as reported by the code above.\n",
    "# Please enter only a number between 0 and 1 inclusive.\n",
    "# Please do not remove this comment.\n",
    "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
    "    pass\n",
    "    # Please enter your score in the scope of the above conditional.\n",
    "    ##### YOUR CODE HERE\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
